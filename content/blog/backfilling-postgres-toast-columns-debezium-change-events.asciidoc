---
title: "Backfilling Postgres TOAST Columns in Debezium Data Change Events"
date: 2025-04-16T11:25:00+02:00
draft: false
markup: adoc
---
:source-highlighter: rouge
:rouge-style: base16.dark
:icons: font
:imagesdir: /images
ifdef::env-github[]
:imagesdir: ../../static/images
endif::[]



partial updates
reselect: latency, location, batching

<!--more-->

## Flink SQL Connectors for Apache Kafka



[source,sql,linenums=true]
----

----
<1> The `id` field maps to the key of incoming Kafka messages


If you'd like to experiment with the different connectors and data formats for ingesting Debezium data change events from Kafka into Flink SQL by yourself,
check out https://github.com/gunnarmorling/streaming-examples/tree/main/debezium-kafka-flink-sql-ingest[this project] in my _stream-examples_ repository which contains Flink jobs for all the different configurations.
