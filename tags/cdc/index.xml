<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cdc on Gunnar Morling</title>
    <link>https://www.morling.dev/tags/cdc/</link>
    <description>Recent content in cdc on Gunnar Morling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019 - 2025 Gunnar Morling</copyright>
    <lastBuildDate>Sun, 07 Dec 2025 10:05:00 +0100</lastBuildDate>
    <atom:link href="https://www.morling.dev/tags/cdc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>You Gotta Push If You Wanna Pull</title>
      <link>https://www.morling.dev/blog/you-gotta-push-if-you-wanna-pull/</link>
      <pubDate>Sun, 07 Dec 2025 10:05:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/you-gotta-push-if-you-wanna-pull/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_materialized_views&#34;&gt;Materialized Views&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_embracing_data_duplication&#34;&gt;Embracing Data Duplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_streams_for_machines_tables_for_humans&#34;&gt;Streams for machines, tables for humans&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Historically, data management systems have been built around the notion of &lt;em&gt;pull queries&lt;/em&gt;: users query data which, for instance, is stored in tables in an RDBMS, Parquet files in a data lake, or a full-text index in Elasticsearch. When a user issues a query, the engine will produce the result set at that point in time by churning through the data set and finding all matching records (oftentimes sped up by utilizing indexes).&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Postgres Replication Slots: Confirmed Flush LSN vs. Restart LSN</title>
      <link>https://www.morling.dev/blog/postgres-replication-slots-confirmed-flush-lsn-vs-restart-lsn/</link>
      <pubDate>Tue, 05 Aug 2025 13:55:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/postgres-replication-slots-confirmed-flush-lsn-vs-restart-lsn/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_confirmed_flush_sn_tracking_consumer_progress&#34;&gt;confirmed_flush_sn: Tracking Consumer Progress&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_restart_lsn_handling_concurrent_transactions&#34;&gt;restart_lsn: Handling Concurrent Transactions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_mid_transaction_recovery&#34;&gt;Mid-Transaction Recovery&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_looking_forward_streaming_in_progress_transactions&#34;&gt;Looking Forward: Streaming In-Progress Transactions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Replication slots in Postgres keep track of how far consumers have read a replication stream.&#xA;After a restart, consumers—​either Postgres read replicas or external tools for change data capture (CDC), like &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;—resume reading from the last confirmed log sequence number (LSN) of their replication slot. The slot prevents the database from disposing of required log segments, allowing safe resumption after downtime.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;In this post, we are going to take a look at why Postgres replication slots don’t have one but two LSN-related attributes: &lt;code&gt;restart_lsn&lt;/code&gt; and &lt;code&gt;confirmed_flush_lsn&lt;/code&gt;.&#xA;Understanding the difference between the two is crucial for troubleshooting replication issues, optimizing WAL retention, and avoiding common pitfalls in production environments.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Mastering Postgres Replication Slots: Preventing WAL Bloat and Other Production Issues</title>
      <link>https://www.morling.dev/blog/mastering-postgres-replication-slots/</link>
      <pubDate>Tue, 08 Jul 2025 13:55:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/mastering-postgres-replication-slots/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_the_pgoutput_logical_decoding_output_plug_in&#34;&gt;Use the pgoutput Logical Decoding Output Plug-in&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_define_a_maximum_replication_slot_size&#34;&gt;Define a Maximum Replication Slot Size&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_enable_heartbeats&#34;&gt;Enable Heartbeats&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_table_level_publications&#34;&gt;Use Table-level Publications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_column_and_row_filters&#34;&gt;Use Column and Row Filters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_enable_fail_over_slots&#34;&gt;Enable Fail-Over Slots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_consider_using_replica_identity_full&#34;&gt;Consider Using Replica Identity FULL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_monitor_monitor_monitor&#34;&gt;Monitor, Monitor, Monitor!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_drop_unused_replication_slots&#34;&gt;Drop Unused Replication Slots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the last couple of years, I’ve helped dozens of users and organizations to build Change Data Capture (CDC) pipelines for their Postgres databases. A key concern in that process is setting up and managing replication slots, which are Postgres&amp;#39; mechanism for making sure that any segments of the write-ahead log (WAL) of the database are kept around until they have been processed by registered replication consumers.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;When not being careful, a replication slot may cause unduly large amounts of WAL segments to be retained by the database. This post describes best practices helping to prevent this and other issues, discussing aspects like heartbeats, replication slot failover, monitoring, the management of Postgres publications, and more. While this is primarily based on my experience of using replication slots via &lt;a href=&#34;https://debezium.io/documentation/reference/stable/connectors/postgresql.html&#34;&gt;Debezium’s Postgres connector&lt;/a&gt;, the principles are generally applicable and are worth considering also when using other CDC tools for Postgres based on logical replication.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Backfilling Postgres TOAST Columns in Debezium Data Change Events</title>
      <link>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</link>
      <pubDate>Mon, 26 May 2025 16:40:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_debezium_reselect_postprocessor&#34;&gt;Debezium Reselect Postprocessor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_datastream_api&#34;&gt;Flink DataStream API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_with_over_aggregation&#34;&gt;Flink SQL With OVER Aggregation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_process_table_functions&#34;&gt;Flink Process Table Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_discussion&#34;&gt;Summary and Discussion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;Postgres logical replication, while powerful for capturing real-time data changes, presents challenges with TOAST columns,&#xA;whose values can be absent from data change events in specific situations.&#xA;This post discusses how Debezium addresses this through its built-in reselect post processor,&#xA;then explores more robust solutions leveraging Apache Flink’s capabilities for stateful stream processing,&#xA;including Flink SQL and the brand-new process table functions (PTFs) in Flink 2.1.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A Deep Dive Into Ingesting Debezium Events From Kafka With Flink SQL</title>
      <link>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</link>
      <pubDate>Wed, 16 Apr 2025 11:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_connectors_for_apache_kafka&#34;&gt;Flink SQL Connectors for Apache Kafka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_in_append_only_mode&#34;&gt;The Apache Kafka SQL Connector in Append-Only Mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_as_a_changelog_source&#34;&gt;The Apache Kafka SQL Connector As a Changelog Source&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_upsert_kafka_sql_connector&#34;&gt;The Upsert Kafka SQL Connector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the years, I’ve spoken quite a bit about the use cases for processing &lt;a href=&#34;https://2023.javazone.no/program/355869fa-5aa0-43a7-abd2-7c5250e10bcd&#34;&gt;Debezium data change events with Apache Flink&lt;/a&gt;,&#xA;such as metadata enrichment, building denormalized data views, and creating data contracts for your CDC streams.&#xA;One detail I haven’t covered in depth so far is how to actually ingest Debezium change events from a Kafka topic into Flink,&#xA;in particular via Flink SQL.&#xA;Several connectors and data formats exist for this, which can make things somewhat confusing at first.&#xA;So let’s dive into the different options and the considerations around them!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>CDC Is a Feature Not a Product</title>
      <link>https://www.morling.dev/blog/cdc-is-a-feature-not-a-product/</link>
      <pubDate>Fri, 18 Oct 2024 15:55:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/cdc-is-a-feature-not-a-product/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;During and after my time as the lead of &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;,&#xA;a widely used open-source platform for Change Data Capture (CDC) for a variety of database,&#xA;I got repeatedly asked whether I’d be interested in creating a company around CDC.&#xA;VCs, including wellknown household names, did and do reach out to me,&#xA;pitching this idea.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Can Debezium Lose Events?</title>
      <link>https://www.morling.dev/blog/can-debezium-lose-events/</link>
      <pubDate>Tue, 14 Nov 2023 15:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/can-debezium-lose-events/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This question came up on the Data Engineering sub-reddit the other day:&#xA;&lt;a href=&#34;https://old.reddit.com/r/dataengineering/comments/17ttw5e/can_debezium_loose_updates/&#34;&gt;Can Debezium lose any events&lt;/a&gt;?&#xA;I.e. can there be a situation where a record in a database get inserted, updated, or deleted, but Debezium fails to capture that event from the transaction log and propagate it to downstream consumers?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Postgres 15: Logical Decoding Row Filters With Debezium</title>
      <link>https://www.morling.dev/blog/postgres-15-logical-decoding-row-filters-with-debezium/</link>
      <pubDate>Thu, 15 Dec 2022 00:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/postgres-15-logical-decoding-row-filters-with-debezium/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_using_logical_decoding_row_filters_with_debezium&#34;&gt;Using Logical Decoding Row Filters With Debezium&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_observing_filtered_change_events&#34;&gt;Observing Filtered Change Events&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_wrap_up&#34;&gt;Wrap-Up&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post &lt;a href=&#34;https://www.decodable.co/blog/postgres-15-logical-decoding-row-filters-with-debezium&#34;&gt;originally appeared&lt;/a&gt; on the Decodable blog.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Since &lt;a href=&#34;https://www.postgresql.org/docs/current/logicaldecoding-explanation.html&#34;&gt;logical decoding&lt;/a&gt; was added to Postgres in version 9.4, this powerful feature for capturing changes from the write-ahead log of the database has been continuously improved. &lt;a href=&#34;https://www.postgresql.org/about/news/postgresql-15-released-2526/&#34;&gt;Postgres 15&lt;/a&gt;, released in October this year, added support for fine-grained control over which columns (by means of column lists) and rows (via row filters) should be exported from captured tables. This means, in relational terminology, projections and filters are now natively supported by Postgres change event publications.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>The Insatiable Postgres Replication Slot</title>
      <link>https://www.morling.dev/blog/insatiable-postgres-replication-slot/</link>
      <pubDate>Wed, 30 Nov 2022 14:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/insatiable-postgres-replication-slot/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_observation&#34;&gt;The Observation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_solution&#34;&gt;The Solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_take_away&#34;&gt;Take Away&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;While working on a demo for processing change events from Postgres with Apache Flink,&#xA;I noticed an interesting phenomenon:&#xA;A Postgres database which I had set up for that demo on Amazon RDS, ran out of disk space.&#xA;The machine had a disk size of 200 GiB which was fully used up in the course of less than two weeks.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Now a common cause for this kind of issue are replication slots which are not advanced:&#xA;in that case, Postgres will hold on to all WAL segments after the latest log sequence number (&lt;a href=&#34;https://pgpedia.info/l/LSN-log-sequence-number.html&#34;&gt;LSN&lt;/a&gt;) which was confirmed for that slot.&#xA;Indeed I had set up a replication slot (via the &lt;a href=&#34;https://www.decodable.co/connectors/postgres-cdc&#34;&gt;Decodable CDC source connector for Postgres&lt;/a&gt;, which is based on &lt;a href=&#34;https://debezium.io&#34;&gt;Debezium&lt;/a&gt;).&#xA;I then had stopped that connector, causing the slot to become inactive.&#xA;The problem was though that I was really sure that there was no traffic in that database whatsoever!&#xA;What could cause a WAL growth of ~18 GB/day then?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Debezium and Friends – Conference Talks 2021</title>
      <link>https://www.morling.dev/blog/debezium-talks-2021/</link>
      <pubDate>Tue, 02 Nov 2021 10:50:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/debezium-talks-2021/</guid>
      <description>Table of Contents Don’t Fear Outdated Caches – Change Data Capture to the Rescue! Change Data Streaming Patterns in Distributed Systems Analyzing Real-time Order Deliveries using CDC with Debezium and Pinot Dissecting our Legacy: The Strangler Fig Pattern with Apache Kafka, Debezium and MongoDB Bonus: Debezium at the Trino Community Broadcast Learning More If you love to attend conferences around the world without actually leaving the comfort of your house, 2021 certainly was (and is!</description>
    </item>
    <item>
      <title>Single Message Transformations - The Swiss Army Knife of Kafka Connect</title>
      <link>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</link>
      <pubDate>Thu, 14 May 2020 15:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_format_conversions&#34;&gt;Format Conversions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_ensuring_backwards_compatibility&#34;&gt;Ensuring Backwards Compatibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_filtering_and_routing&#34;&gt;Filtering and Routing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_tombstone_handling&#34;&gt;Tombstone Handling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_externalizing_large_payloads&#34;&gt;Externalizing Large Payloads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_learning_more&#34;&gt;Learning More&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Do you remember Angus &amp;#34;Mac&amp;#34; MacGyver?&#xA;The always creative protagonist of the popular 80ies/90ies TV show, who could solve about any problem with nothing more than a Swiss Army knife, duct tape, shoe strings and a paper clip?&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The single message transformations (SMTs) of Kafka Connect are almost as versatile as MacGyver’s Swiss Army knife:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;ulist&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the timezone or format of date/time message fields?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the topic a specific message gets sent to?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to filter out specific records?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;SMTs can be the answer to these and many other questions that come up in the context of Kafka Connect.&#xA;Applied to source or sink connectors,&#xA;SMTs allow to modify Kafka records before they are sent to Kafka, or after they are consumed from a topic, respectively.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
