<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on Gunnar Morling</title>
    <link>https://www.morling.dev/tags/kafka/</link>
    <description>Recent content in kafka on Gunnar Morling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2019 - 2025 Gunnar Morling</copyright>
    <lastBuildDate>Mon, 03 Nov 2025 18:02:00 +0100</lastBuildDate>
    <atom:link href="https://www.morling.dev/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>&#34;You Don&#39;t Need Kafka, Just Use Postgres&#34; Considered Harmful</title>
      <link>https://www.morling.dev/blog/you-dont-need-kafka-just-use-postgres-considered-harmful/</link>
      <pubDate>Mon, 03 Nov 2025 18:02:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/you-dont-need-kafka-just-use-postgres-considered-harmful/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Looking to make it to the front page of HackerNews? Then writing a post arguing that &amp;#34;Postgres is enough&amp;#34;, or why &amp;#34;you donâ€™t need Kafka at your scale&amp;#34; is a pretty failsafe way of achieving exactly that. No matter how often it has been discussed before, this topic is always doing well. And sure, whatâ€™s not to love about that? I mean, it has it all: Postgres, everybodyâ€™s most favorite RDBMSâ€”â€‹check! Keeping things lean and easyâ€”â€‹sure, count me in! A somewhat spicy takeâ€”â€‹bring it on!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>What If We Could Rebuild Kafka From Scratch?</title>
      <link>https://www.morling.dev/blog/what-if-we-could-rebuild-kafka-from-scratch/</link>
      <pubDate>Thu, 24 Apr 2025 16:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/what-if-we-could-rebuild-kafka-from-scratch/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The last few days I spent some time digging into the recently announced &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-1150%3A+Diskless+Topics&#34;&gt;KIP-1150&lt;/a&gt; (&amp;#34;Diskless Kafka&amp;#34;), as well &lt;a href=&#34;https://github.com/AutoMQ/automq&#34;&gt;AutoMQâ€™s Kafka fork&lt;/a&gt;, tightly integrating Apache Kafka and object storage, such as S3. Following the example set by WarpStream, these projects aim to substantially improve the experience of using Kafka in cloud environments, providing better elasticity, drastically reducing cost, and paving the way towards native lakehouse integration.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This got me thinking, if we were to start all over and develop a durable cloud-native event log from scratchâ€”â€‹Kafka.next if you willâ€”â€‹which traits and characteristics would be desirable for this to have? Separating storage and compute and object store support would be table stakes, but what else should be there? Having used Kafka for many years for building event-driven applications as well as for running realtime ETL and change data capture pipelines, hereâ€™s my personal wishlist:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A Deep Dive Into Ingesting Debezium Events From Kafka With Flink SQL</title>
      <link>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</link>
      <pubDate>Wed, 16 Apr 2025 11:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_connectors_for_apache_kafka&#34;&gt;Flink SQL Connectors for Apache Kafka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_in_append_only_mode&#34;&gt;The Apache Kafka SQL Connector in Append-Only Mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_as_a_changelog_source&#34;&gt;The Apache Kafka SQL Connector As a Changelog Source&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_upsert_kafka_sql_connector&#34;&gt;The Upsert Kafka SQL Connector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the years, Iâ€™ve spoken quite a bit about the use cases for processing &lt;a href=&#34;https://2023.javazone.no/program/355869fa-5aa0-43a7-abd2-7c5250e10bcd&#34;&gt;Debezium data change events with Apache Flink&lt;/a&gt;,&#xA;such as metadata enrichment, building denormalized data views, and creating data contracts for your CDC streams.&#xA;One detail I havenâ€™t covered in depth so far is how to actually ingest Debezium change events from a Kafka topic into Flink,&#xA;in particular via Flink SQL.&#xA;Several connectors and data formats exist for this, which can make things somewhat confusing at first.&#xA;So letâ€™s dive into the different options and the considerations around them!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Building a Native Binary for Apache Kafka on macOS</title>
      <link>https://www.morling.dev/blog/building-native-binary-for-apache-kafka-macos/</link>
      <pubDate>Mon, 07 Apr 2025 12:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/building-native-binary-for-apache-kafka-macos/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_kip_974_docker_image_for_graalvm_based_native_kafka_broker&#34;&gt;KIP-974: Docker Image for GraalVM based Native Kafka Broker&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;With help of the GraalVM configuration developed for KIP-974 (Docker Image for GraalVM based Native Kafka Broker),&#xA;you can easily build a self-contained native binary for Apache Kafka.&#xA;Read on to learn how you can build a native Kafka executable yourself,&#xA;starting in milli-seconds, making it a perfect fit for development and testing purposes.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;When I wrote about &lt;a href=&#34;https://www.morling.dev/blog/jep-483-aot-class-loading-linking/&#34;&gt;ahead-of-time class loading and linking in Java 24&lt;/a&gt; recently,&#xA;I also published the start-up time for Apache Kafka as a native binary for comparison.&#xA;This was done via Docker, as thereâ€™s no pre-built native binary of Kafka available for the operating system Iâ€™m running on, macOS.&#xA;But there is a native Kafka container image, so this is what I chose for the sake of convenience.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Now, running in a container adds a little bit of overhead of course,&#xA;so it wasnâ€™t a surprise when Thomas WÃ¼rthinger, lead of the GraalVM project at Oracle,&#xA;&lt;a href=&#34;https://bsky.app/profile/thomaswue.dev/post/3lloypreatk2s&#34;&gt;brought up the question&lt;/a&gt; what the value would be when running Kafka natively on macOS.&#xA;Needless to say I canâ€™t leave this kind of nice nerd snipe pass,&#xA;so I set out to learn how to build a native Kafka binary on macOS, using GraalVM.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Let&#39;s Take a Look at... KIP-932: Queues for Kafka!</title>
      <link>https://www.morling.dev/blog/kip-932-queues-for-kafka/</link>
      <pubDate>Wed, 05 Mar 2025 12:35:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/kip-932-queues-for-kafka/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_towards_queue_support_in_kafkaintroducing_share_groups&#34;&gt;Towards Queue Support in Kafkaâ€”â€‹Introducing Share Groups&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_share_groups_in_action&#34;&gt;Share Groups in Action&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_retry_behavior_and_state_management&#34;&gt;Retry Behavior and State Management&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_share_group_state_persistence&#34;&gt;Share Group State Persistence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_outlook&#34;&gt;Summary and Outlook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;In the &amp;#34;Letâ€™s Take a Look atâ€¦â€‹!&amp;#34; blog series I am going to explore interesting projects, developments and technologies in the data and streaming space. This can be KIPs and FLIPs, open-source projects, services, and more. The idea is to get some hands-on experience, learn about potential use cases and applications, and understand the trade-offs involved. If you think thereâ€™s a specific subject I should take a look at, let me know in the comments below!&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://www.morling.dev/images/kip_932_1.jpg&#34; alt=&#34;kip 932 1&#34; width=&#34;333px&#34;/&gt;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;That guy above? Yep, thatâ€™s me, whenever someone says &amp;#34;Kafka queue&amp;#34;. Because, thatâ€™s not what Apache Kafka is. At its core, Kafka is a distributed durable event log. Producers write events to a topic, organized in partitions which are distributed amongst the brokers of a Kafka cluster. Consumers, organized in groups, divide the partitions they process amongst themselves, so that each partition of a topic is read by exactly one consumer in the group.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>An Ideation for Kubernetes-native Kafka Connect</title>
      <link>https://www.morling.dev/blog/ideation-kubernetes-native-kafka-connect/</link>
      <pubDate>Tue, 06 Sep 2022 14:20:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/ideation-kubernetes-native-kafka-connect/</guid>
      <description>Table of Contents Standalone or Distributed? Issues with Kafka Connect on Kubernetes A Vision for Kubernetes-native Kafka Connect Kafka Connect, part of the Apache Kafka project, is a development framework and runtime for connectors which either ingest data into Kafka clusters (source connectors) or propagate data from Kafka into external systems (sink connectors). A diverse ecosystem of ready-made connectors has come to life on top of Kafka Connect, which lets you connect all kinds of data stores, APIs, and other systems to Kafka in a no-code approach.</description>
    </item>
    <item>
      <title>Testing Kafka Connectors</title>
      <link>https://www.morling.dev/blog/testing-kafka-connectors/</link>
      <pubDate>Thu, 25 Aug 2022 09:20:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/testing-kafka-connectors/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_unit_tests&#34;&gt;Unit Tests&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_integration_tests&#34;&gt;Integration Tests&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_wrap_up&#34;&gt;Wrap-Up&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/#connect&#34;&gt;Kafka Connect&lt;/a&gt; is a key factor for the wide-spread adoption of Apache Kafka:&#xA;a framework and runtime environment for connectors,&#xA;it makes the task of getting data either into Kafka or out of Kafka solely a matter of configuration,&#xA;rather than a bespoke programming job.&#xA;Thereâ€™s dozens, if not hundreds, of readymade source and sink connectors,&#xA;allowing you to create no-code data pipelines between all kinds of databases, APIs, and other systems.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;There may be situations though where there is no existing connector matching your requirements,&#xA;in which case you can &lt;a href=&#34;https://kafka.apache.org/documentation/#connect_development&#34;&gt;implement your own&lt;/a&gt; custom connector using the Kafka Connect framework.&#xA;Naturally, this raises the question of how to test such a Kafka connector,&#xA;making sure it propagates the data between the connected external system and Kafka correctly and completely.&#xA;In this blog post Iâ€™d like to focus on testing approaches for Kafka Connect &lt;em&gt;source&lt;/em&gt; connectors,&#xA;i.e. connectors like &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;, which ingest data from an external system into Kafka.&#xA;Very similar strategies can be employed for testing sink connectors, though.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Announcing the First Release of kcctl</title>
      <link>https://www.morling.dev/blog/announcing-first-release-of-kcctl/</link>
      <pubDate>Tue, 21 Dec 2021 17:48:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/announcing-first-release-of-kcctl/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_discussion_and_outlook&#34;&gt;Discussion and Outlook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;ðŸ§¸ &lt;em&gt;Itâ€™s Casey. Casey Cuddle.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;I am very happy to announce the first stable release of &lt;a href=&#34;https://github.com/kcctl/kcctl&#34;&gt;kcctl&lt;/a&gt;,&#xA;a modern and intuitive command line client for &lt;a href=&#34;https://kafka.apache.org/documentation/#connect&#34;&gt;Apache Kafka Connect&lt;/a&gt;!&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Forget about having to memorize and type the right REST API paths and curl flags;&#xA;with kcctl, managing your Kafka connectors is done via concise and logically structured commands,&#xA;modeled after the semantics of the kubectl tool known from Kubernetes.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>O Kafka, Where Art Thou?</title>
      <link>https://www.morling.dev/blog/kafka-where-art-thou/</link>
      <pubDate>Mon, 29 Nov 2021 18:55:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/kafka-where-art-thou/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The other day, I came across an &lt;a href=&#34;https://www.reddit.com/r/java/comments/r2z17a/has_any_one_attempted_to_write_logs_directly_to/&#34;&gt;interesting thread&lt;/a&gt; in the Java sub-reddit, with someone asking:&#xA;&amp;#34;Has anyone attempted to write logs directly to Kafka?&amp;#34;.&#xA;This triggered a number of thoughts and questions for myself,&#xA;in particular how one should deal in an application when an attempt to send messages to Kafka fails,&#xA;for instance due to some network connectivity issue?&#xA;What do you do when you cannot reach the Kafka broker?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Three Plus Some Lovely Kafka Trends</title>
      <link>https://www.morling.dev/blog/three-plus-some-lovely-kafka-trends/</link>
      <pubDate>Fri, 28 May 2021 10:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/three-plus-some-lovely-kafka-trends/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_cambrian_explosion_of_connectors&#34;&gt;Cambrian Explosion of Connectors&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_democratization_of_data_pipelines&#34;&gt;Democratization of Data Pipelines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_stream_processing_for_everyone&#34;&gt;Stream Processing for Everyone&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_honorable_mentions&#34;&gt;Honorable Mentions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the course of the last few months, Iâ€™ve had the pleasure to serve on the &lt;a href=&#34;https://www.kafka-summit.org/&#34;&gt;Kafka Summit&lt;/a&gt; program committee and review several hundred session abstracts for the three Summits happening this year (Europe, APAC, Americas).&#xA;Thatâ€™s not only a big honour, but also a unique opportunity to learn what excites people currently in the Kafka eco-system&#xA;(and yes, itâ€™s a fair amount of work, too ;).&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;While voting on the proposals, and also generally aspiring to stay informed of whatâ€™s going on in the Kafka community at large, I noticed a few repeating themes and topics which I thought would be interesting to share&#xA;(without touching on any specific talks of course).&#xA;At first I meant to put this out via a Twitter thread, but then it became a bit too long for that, so I decided to write this quick blog post instead.&#xA;Here it goes!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Exploring ZooKeeper-less Kafka</title>
      <link>https://www.morling.dev/blog/exploring-zookeeper-less-kafka/</link>
      <pubDate>Mon, 17 May 2021 18:45:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/exploring-zookeeper-less-kafka/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_trying_zk_less_kafka_yourself&#34;&gt;Trying ZK-less Kafka Yourself&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_taking_brokers_down&#34;&gt;Taking Brokers Down&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_wrap_up&#34;&gt;Wrap-Up&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Sometimes, less is more.&#xA;One case where thatâ€™s certainly true is dependencies.&#xA;And so it shouldnâ€™t come at a surprise that the &lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Apache Kafka&lt;/a&gt; community is eagerly awaiting the removal of the dependency to the &lt;a href=&#34;https://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt; service,&#xA;which currently is used for storing Kafka metadata (e.g. about topics and partitions) as well as for the purposes of leader election in the cluster.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The Kafka improvement proposal &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&#34;&gt;KIP-500&lt;/a&gt;&#xA;(&amp;#34;Replace ZooKeeper with a Self-Managed Metadata Quorum&amp;#34;)&#xA;promises to make life better for users in many regards:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;ulist&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Better getting started and operational experience by requiring to run only one system, Kafka, instead of two&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Removing potential for discrepancies of metadata state between ZooKeeper and the Kafka controller&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Simplifying configuration, for instance when it comes to security&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Better scalability, e.g. in terms of number of partitions; faster execution of operations like topic creation&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Single Message Transformations - The Swiss Army Knife of Kafka Connect</title>
      <link>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</link>
      <pubDate>Thu, 14 May 2020 15:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_format_conversions&#34;&gt;Format Conversions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_ensuring_backwards_compatibility&#34;&gt;Ensuring Backwards Compatibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_filtering_and_routing&#34;&gt;Filtering and Routing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_tombstone_handling&#34;&gt;Tombstone Handling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_externalizing_large_payloads&#34;&gt;Externalizing Large Payloads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_learning_more&#34;&gt;Learning More&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Do you remember Angus &amp;#34;Mac&amp;#34; MacGyver?&#xA;The always creative protagonist of the popular 80ies/90ies TV show, who could solve about any problem with nothing more than a Swiss Army knife, duct tape, shoe strings and a paper clip?&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The single message transformations (SMTs) of Kafka Connect are almost as versatile as MacGyverâ€™s Swiss Army knife:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;ulist&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the timezone or format of date/time message fields?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the topic a specific message gets sent to?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to filter out specific records?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;SMTs can be the answer to these and many other questions that come up in the context of Kafka Connect.&#xA;Applied to source or sink connectors,&#xA;SMTs allow to modify Kafka records before they are sent to Kafka, or after they are consumed from a topic, respectively.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
