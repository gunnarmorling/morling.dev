<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>debezium on Gunnar Morling</title>
    <link>https://www.morling.dev/tags/debezium/</link>
    <description>Recent content in debezium on Gunnar Morling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019 - 2025 Gunnar Morling</copyright>
    <lastBuildDate>Tue, 08 Jul 2025 13:55:00 +0200</lastBuildDate>
    <atom:link href="https://www.morling.dev/tags/debezium/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mastering Postgres Replication Slots: Preventing WAL Bloat and Other Production Issues</title>
      <link>https://www.morling.dev/blog/mastering-postgres-replication-slots/</link>
      <pubDate>Tue, 08 Jul 2025 13:55:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/mastering-postgres-replication-slots/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_the_pgoutput_logical_decoding_output_plug_in&#34;&gt;Use the pgoutput Logical Decoding Output Plug-in&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_define_a_maximum_replication_slot_size&#34;&gt;Define a Maximum Replication Slot Size&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_enable_heartbeats&#34;&gt;Enable Heartbeats&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_table_level_publications&#34;&gt;Use Table-level Publications&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_use_column_and_row_filters&#34;&gt;Use Column and Row Filters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_enable_fail_over_slots&#34;&gt;Enable Fail-Over Slots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_consider_using_replica_identity_full&#34;&gt;Consider Using Replica Identity FULL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_monitor_monitor_monitor&#34;&gt;Monitor, Monitor, Monitor!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_drop_unused_replication_slots&#34;&gt;Drop Unused Replication Slots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the last couple of years, I’ve helped dozens of users and organizations to build Change Data Capture (CDC) pipelines for their Postgres databases. A key concern in that process is setting up and managing replication slots, which are Postgres&amp;#39; mechanism for making sure that any segments of the write-ahead log (WAL) of the database are kept around until they have been processed by registered replication consumers.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;When not being careful, a replication slot may cause unduly large amounts of WAL segments to be retained by the database. This post describes best practices helping to prevent this and other issues, discussing aspects like heartbeats, replication slot failover, monitoring, the management of Postgres publications, and more. While this is primarily based on my experience of using replication slots via &lt;a href=&#34;https://debezium.io/documentation/reference/stable/connectors/postgresql.html&#34;&gt;Debezium’s Postgres connector&lt;/a&gt;, the principles are generally applicable and are worth considering also when using other CDC tools for Postgres based on logical replication.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Backfilling Postgres TOAST Columns in Debezium Data Change Events</title>
      <link>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</link>
      <pubDate>Mon, 26 May 2025 16:40:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_debezium_reselect_postprocessor&#34;&gt;Debezium Reselect Postprocessor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_datastream_api&#34;&gt;Flink DataStream API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_with_over_aggregation&#34;&gt;Flink SQL With OVER Aggregation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_process_table_functions&#34;&gt;Flink Process Table Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_discussion&#34;&gt;Summary and Discussion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;Postgres logical replication, while powerful for capturing real-time data changes, presents challenges with TOAST columns,&#xA;whose values can be absent from data change events in specific situations.&#xA;This post discusses how Debezium addresses this through its built-in reselect post processor,&#xA;then explores more robust solutions leveraging Apache Flink’s capabilities for stateful stream processing,&#xA;including Flink SQL and the brand-new process table functions (PTFs) in Flink 2.1.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A Deep Dive Into Ingesting Debezium Events From Kafka With Flink SQL</title>
      <link>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</link>
      <pubDate>Wed, 16 Apr 2025 11:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_connectors_for_apache_kafka&#34;&gt;Flink SQL Connectors for Apache Kafka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_in_append_only_mode&#34;&gt;The Apache Kafka SQL Connector in Append-Only Mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_as_a_changelog_source&#34;&gt;The Apache Kafka SQL Connector As a Changelog Source&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_upsert_kafka_sql_connector&#34;&gt;The Upsert Kafka SQL Connector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the years, I’ve spoken quite a bit about the use cases for processing &lt;a href=&#34;https://2023.javazone.no/program/355869fa-5aa0-43a7-abd2-7c5250e10bcd&#34;&gt;Debezium data change events with Apache Flink&lt;/a&gt;,&#xA;such as metadata enrichment, building denormalized data views, and creating data contracts for your CDC streams.&#xA;One detail I haven’t covered in depth so far is how to actually ingest Debezium change events from a Kafka topic into Flink,&#xA;in particular via Flink SQL.&#xA;Several connectors and data formats exist for this, which can make things somewhat confusing at first.&#xA;So let’s dive into the different options and the considerations around them!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Thoughts On Moving Debezium to the Commonhaus Foundation</title>
      <link>https://www.morling.dev/blog/thoughts-on-moving-debezium-to-commonhaus-foundation/</link>
      <pubDate>Wed, 27 Nov 2024 17:25:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/thoughts-on-moving-debezium-to-commonhaus-foundation/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;If you are following the news around Debezium—​an open-source platform for Change Data Capture (CDC) for a variety of databases—​you may have seen the announcement that the project is in the process of &lt;a href=&#34;https://debezium.io/blog/2024/11/04/debezium-moving-to-commonhaus/&#34;&gt;moving to the Commonhaus Foundation&lt;/a&gt;. I think this is excellent news for the Debezium project, its community, and open-source CDC at large. In this post I’d like to share some more context on why I am so excited about this development.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>CDC Is a Feature Not a Product</title>
      <link>https://www.morling.dev/blog/cdc-is-a-feature-not-a-product/</link>
      <pubDate>Fri, 18 Oct 2024 15:55:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/cdc-is-a-feature-not-a-product/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;During and after my time as the lead of &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;,&#xA;a widely used open-source platform for Change Data Capture (CDC) for a variety of database,&#xA;I got repeatedly asked whether I’d be interested in creating a company around CDC.&#xA;VCs, including wellknown household names, did and do reach out to me,&#xA;pitching this idea.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Can Debezium Lose Events?</title>
      <link>https://www.morling.dev/blog/can-debezium-lose-events/</link>
      <pubDate>Tue, 14 Nov 2023 15:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/can-debezium-lose-events/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This question came up on the Data Engineering sub-reddit the other day:&#xA;&lt;a href=&#34;https://old.reddit.com/r/dataengineering/comments/17ttw5e/can_debezium_loose_updates/&#34;&gt;Can Debezium lose any events&lt;/a&gt;?&#xA;I.e. can there be a situation where a record in a database get inserted, updated, or deleted, but Debezium fails to capture that event from the transaction log and propagate it to downstream consumers?&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Debezium and Friends – Conference Talks 2021</title>
      <link>https://www.morling.dev/blog/debezium-talks-2021/</link>
      <pubDate>Tue, 02 Nov 2021 10:50:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/debezium-talks-2021/</guid>
      <description>Table of Contents Don’t Fear Outdated Caches – Change Data Capture to the Rescue! Change Data Streaming Patterns in Distributed Systems Analyzing Real-time Order Deliveries using CDC with Debezium and Pinot Dissecting our Legacy: The Strangler Fig Pattern with Apache Kafka, Debezium and MongoDB Bonus: Debezium at the Trino Community Broadcast Learning More If you love to attend conferences around the world without actually leaving the comfort of your house, 2021 certainly was (and is!</description>
    </item>
    <item>
      <title>Single Message Transformations - The Swiss Army Knife of Kafka Connect</title>
      <link>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</link>
      <pubDate>Thu, 14 May 2020 15:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_format_conversions&#34;&gt;Format Conversions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_ensuring_backwards_compatibility&#34;&gt;Ensuring Backwards Compatibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_filtering_and_routing&#34;&gt;Filtering and Routing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_tombstone_handling&#34;&gt;Tombstone Handling&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_externalizing_large_payloads&#34;&gt;Externalizing Large Payloads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_limitations&#34;&gt;Limitations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_learning_more&#34;&gt;Learning More&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Do you remember Angus &amp;#34;Mac&amp;#34; MacGyver?&#xA;The always creative protagonist of the popular 80ies/90ies TV show, who could solve about any problem with nothing more than a Swiss Army knife, duct tape, shoe strings and a paper clip?&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The single message transformations (SMTs) of Kafka Connect are almost as versatile as MacGyver’s Swiss Army knife:&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;ulist&#34;&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the timezone or format of date/time message fields?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to change the topic a specific message gets sent to?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to filter out specific records?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;SMTs can be the answer to these and many other questions that come up in the context of Kafka Connect.&#xA;Applied to source or sink connectors,&#xA;SMTs allow to modify Kafka records before they are sent to Kafka, or after they are consumed from a topic, respectively.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
