<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>flink on Gunnar Morling</title>
    <link>https://www.morling.dev/tags/flink/</link>
    <description>Recent content in flink on Gunnar Morling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019 - 2025 Gunnar Morling</copyright>
    <lastBuildDate>Wed, 18 Jun 2025 15:30:00 +0200</lastBuildDate>
    <atom:link href="https://www.morling.dev/tags/flink/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>This AI Agent Should Have Been a SQL Query</title>
      <link>https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/</link>
      <pubDate>Wed, 18 Jun 2025 15:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_need_to_interact_with_llms&#34;&gt;Agents Need to Interact With LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_should_be_event_driven&#34;&gt;Agents Should Be Event-Driven&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_need_context&#34;&gt;Agents Need Context&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_require_memory&#34;&gt;Agents Require Memory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_when_sql_is_not_enough&#34;&gt;When SQL Is Not Enough&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_parting_thoughts&#34;&gt;Parting Thoughts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;AI Agents have improved in leaps and bounds in recent times, moving beyond simple chatbots to sophisticated, autonomous systems. This post explores a novel approach to building agentic systems: using the power of streaming SQL queries. Discover how platforms like Apache Flink can transform the development of AI Agents, offering benefits in consistency, scalability, and developer experience.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Backfilling Postgres TOAST Columns in Debezium Data Change Events</title>
      <link>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</link>
      <pubDate>Mon, 26 May 2025 16:40:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/backfilling-postgres-toast-columns-debezium-change-events/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_debezium_reselect_postprocessor&#34;&gt;Debezium Reselect Postprocessor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_datastream_api&#34;&gt;Flink DataStream API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_with_over_aggregation&#34;&gt;Flink SQL With OVER Aggregation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_process_table_functions&#34;&gt;Flink Process Table Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_discussion&#34;&gt;Summary and Discussion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;Postgres logical replication, while powerful for capturing real-time data changes, presents challenges with TOAST columns,&#xA;whose values can be absent from data change events in specific situations.&#xA;This post discusses how Debezium addresses this through its built-in reselect post processor,&#xA;then explores more robust solutions leveraging Apache Flink’s capabilities for stateful stream processing,&#xA;including Flink SQL and the brand-new process table functions (PTFs) in Flink 2.1.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A Deep Dive Into Ingesting Debezium Events From Kafka With Flink SQL</title>
      <link>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</link>
      <pubDate>Wed, 16 Apr 2025 11:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/ingesting-debezium-events-from-kafka-with-flink-sql/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_flink_sql_connectors_for_apache_kafka&#34;&gt;Flink SQL Connectors for Apache Kafka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_in_append_only_mode&#34;&gt;The Apache Kafka SQL Connector in Append-Only Mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_apache_kafka_sql_connector_as_a_changelog_source&#34;&gt;The Apache Kafka SQL Connector As a Changelog Source&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_upsert_kafka_sql_connector&#34;&gt;The Upsert Kafka SQL Connector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the years, I’ve spoken quite a bit about the use cases for processing &lt;a href=&#34;https://2023.javazone.no/program/355869fa-5aa0-43a7-abd2-7c5250e10bcd&#34;&gt;Debezium data change events with Apache Flink&lt;/a&gt;,&#xA;such as metadata enrichment, building denormalized data views, and creating data contracts for your CDC streams.&#xA;One detail I haven’t covered in depth so far is how to actually ingest Debezium change events from a Kafka topic into Flink,&#xA;in particular via Flink SQL.&#xA;Several connectors and data formats exist for this, which can make things somewhat confusing at first.&#xA;So let’s dive into the different options and the considerations around them!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Maven, What Are You Waiting For?!</title>
      <link>https://www.morling.dev/blog/maven-what-are-you-waiting-for/</link>
      <pubDate>Sun, 18 Dec 2022 13:45:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/maven-what-are-you-waiting-for/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;As part of my &lt;a href=&#34;https://www.morling.dev/blog/why-i-joined-decodable/&#34;&gt;new job&lt;/a&gt; at Decodable,&#xA;I am also planning to contribute to the &lt;a href=&#34;https://flink.apache.org/&#34;&gt;Apache Flink&lt;/a&gt; project&#xA;(as Decodable’s fully-managed &lt;a href=&#34;https://www.decodable.co/product&#34;&gt;stream processing platform&lt;/a&gt; is based on Flink).&#xA;Right now, I am in the process of familiarizing myself with the Flink code base,&#xA;and as such I am of course building the project from source, too.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Why I Joined Decodable</title>
      <link>https://www.morling.dev/blog/why-i-joined-decodable/</link>
      <pubDate>Thu, 03 Nov 2022 15:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/why-i-joined-decodable/</guid>
      <description>Table of Contents The Space: Real-Time Stream Processing The Environment: A Start-up The Team: One of a Kind Outlook It’s my first week as a software engineer at Decodable, a start-up building a serverless real-time data platform! When I shared this news on social media yesterday, folks were not only super supportive and excited for me (thank you so much for all the nice words and wishes!), but some also asked about the reasons behind my decision for switching jobs and going to a start-up, after having worked for Red Hat for the last few years.</description>
    </item>
  </channel>
</rss>
