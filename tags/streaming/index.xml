<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>streaming on Gunnar Morling</title>
    <link>https://www.morling.dev/tags/streaming/</link>
    <description>Recent content in streaming on Gunnar Morling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019 - 2025 Gunnar Morling</copyright>
    <lastBuildDate>Sun, 07 Dec 2025 10:05:00 +0100</lastBuildDate>
    <atom:link href="https://www.morling.dev/tags/streaming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>You Gotta Push If You Wanna Pull</title>
      <link>https://www.morling.dev/blog/you-gotta-push-if-you-wanna-pull/</link>
      <pubDate>Sun, 07 Dec 2025 10:05:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/you-gotta-push-if-you-wanna-pull/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_materialized_views&#34;&gt;Materialized Views&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_embracing_data_duplication&#34;&gt;Embracing Data Duplication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_streams_for_machines_tables_for_humans&#34;&gt;Streams for machines, tables for humans&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Historically, data management systems have been built around the notion of &lt;em&gt;pull queries&lt;/em&gt;: users query data which, for instance, is stored in tables in an RDBMS, Parquet files in a data lake, or a full-text index in Elasticsearch. When a user issues a query, the engine will produce the result set at that point in time by churning through the data set and finding all matching records (oftentimes sped up by utilizing indexes).&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>&#34;You Don&#39;t Need Kafka, Just Use Postgres&#34; Considered Harmful</title>
      <link>https://www.morling.dev/blog/you-dont-need-kafka-just-use-postgres-considered-harmful/</link>
      <pubDate>Mon, 03 Nov 2025 18:02:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/you-dont-need-kafka-just-use-postgres-considered-harmful/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Looking to make it to the front page of HackerNews? Then writing a post arguing that &amp;#34;Postgres is enough&amp;#34;, or why &amp;#34;you don’t need Kafka at your scale&amp;#34; is a pretty failsafe way of achieving exactly that. No matter how often it has been discussed before, this topic is always doing well. And sure, what’s not to love about that? I mean, it has it all: Postgres, everybody’s most favorite RDBMS—​check! Keeping things lean and easy—​sure, count me in! A somewhat spicy take—​bring it on!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>This AI Agent Should Have Been a SQL Query</title>
      <link>https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/</link>
      <pubDate>Wed, 18 Jun 2025 15:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/this-ai-agent-should-have-been-sql-query/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_need_to_interact_with_llms&#34;&gt;Agents Need to Interact With LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_should_be_event_driven&#34;&gt;Agents Should Be Event-Driven&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_need_context&#34;&gt;Agents Need Context&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_agents_require_memory&#34;&gt;Agents Require Memory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_when_sql_is_not_enough&#34;&gt;When SQL Is Not Enough&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_parting_thoughts&#34;&gt;Parting Thoughts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;AI Agents have improved in leaps and bounds in recent times, moving beyond simple chatbots to sophisticated, autonomous systems. This post explores a novel approach to building agentic systems: using the power of streaming SQL queries. Discover how platforms like Apache Flink can transform the development of AI Agents, offering benefits in consistency, scalability, and developer experience.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>&#34;Streaming vs. Batch&#34; Is a Wrong Dichotomy, and I Think It&#39;s Confusing</title>
      <link>https://www.morling.dev/blog/streaming-vs-batch-wrong-dichotomy/</link>
      <pubDate>Wed, 14 May 2025 10:10:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/streaming-vs-batch-wrong-dichotomy/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Often times, &amp;#34;Stream vs. Batch&amp;#34; is discussed as if it’s one &lt;em&gt;or&lt;/em&gt; the other, but to me this does not make that much sense really.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>What If We Could Rebuild Kafka From Scratch?</title>
      <link>https://www.morling.dev/blog/what-if-we-could-rebuild-kafka-from-scratch/</link>
      <pubDate>Thu, 24 Apr 2025 16:25:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/what-if-we-could-rebuild-kafka-from-scratch/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The last few days I spent some time digging into the recently announced &lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-1150%3A+Diskless+Topics&#34;&gt;KIP-1150&lt;/a&gt; (&amp;#34;Diskless Kafka&amp;#34;), as well &lt;a href=&#34;https://github.com/AutoMQ/automq&#34;&gt;AutoMQ’s Kafka fork&lt;/a&gt;, tightly integrating Apache Kafka and object storage, such as S3. Following the example set by WarpStream, these projects aim to substantially improve the experience of using Kafka in cloud environments, providing better elasticity, drastically reducing cost, and paving the way towards native lakehouse integration.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;This got me thinking, if we were to start all over and develop a durable cloud-native event log from scratch—​Kafka.next if you will—​which traits and characteristics would be desirable for this to have? Separating storage and compute and object store support would be table stakes, but what else should be there? Having used Kafka for many years for building event-driven applications as well as for running realtime ETL and change data capture pipelines, here’s my personal wishlist:&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Let&#39;s Take a Look at... KIP-932: Queues for Kafka!</title>
      <link>https://www.morling.dev/blog/kip-932-queues-for-kafka/</link>
      <pubDate>Wed, 05 Mar 2025 12:35:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/kip-932-queues-for-kafka/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_towards_queue_support_in_kafkaintroducing_share_groups&#34;&gt;Towards Queue Support in Kafka—​Introducing Share Groups&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_share_groups_in_action&#34;&gt;Share Groups in Action&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_retry_behavior_and_state_management&#34;&gt;Retry Behavior and State Management&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_share_group_state_persistence&#34;&gt;Share Group State Persistence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_outlook&#34;&gt;Summary and Outlook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph teaser&#34;&gt;&#xA;&lt;p&gt;In the &amp;#34;Let’s Take a Look at…​!&amp;#34; blog series I am going to explore interesting projects, developments and technologies in the data and streaming space. This can be KIPs and FLIPs, open-source projects, services, and more. The idea is to get some hands-on experience, learn about potential use cases and applications, and understand the trade-offs involved. If you think there’s a specific subject I should take a look at, let me know in the comments below!&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;https://www.morling.dev/images/kip_932_1.jpg&#34; alt=&#34;kip 932 1&#34; width=&#34;333px&#34;/&gt;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;That guy above? Yep, that’s me, whenever someone says &amp;#34;Kafka queue&amp;#34;. Because, that’s not what Apache Kafka is. At its core, Kafka is a distributed durable event log. Producers write events to a topic, organized in partitions which are distributed amongst the brokers of a Kafka cluster. Consumers, organized in groups, divide the partitions they process amongst themselves, so that each partition of a topic is read by exactly one consumer in the group.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Get Running with Apache Flink on Kubernetes, part 2 of 2</title>
      <link>https://www.morling.dev/blog/get-running-with-apache-flink-on-kubernetes-2/</link>
      <pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/get-running-with-apache-flink-on-kubernetes-2/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_fault_tolerance_and_high_availability&#34;&gt;Fault Tolerance and High Availability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_manually_triggering_savepoints&#34;&gt;Manually Triggering Savepoints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_observability&#34;&gt;Observability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_bonus_managing_flink_jobs_with_the_heimdall_ui&#34;&gt;Bonus: Managing Flink Jobs With the Heimdall UI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary_and_discussion&#34;&gt;Summary and Discussion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/get-running-with-apache-flink-on-kubernetes-2&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Welcome back to this two-part blog post series about running Apache Flink on Kubernetes, using the Flink Kubernetes operator.&#xA;In &lt;a href=&#34;https://www.morling.dev/blog/get-running-with-apache-flink-on-kubernetes-1&#34;&gt;part one&lt;/a&gt;, we discussed installation and setup of the operator, different deployment types, how to deploy Flink jobs using custom Kubernetes resources, and how to create container images for your own Flink jobs.&#xA;In this part, we’ll focus on aspects such as fault tolerance and high availability of your Flink jobs running on Kubernetes, savepoint management, observability, and more.&#xA;You can find the complete source code for all the examples shown in this series in the Decodable &lt;a href=&#34;https://github.com/decodableco/examples/blob/main/flink-on-kubernetes/&#34;&gt;examples repository&lt;/a&gt; on GitHub: on GitHub.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Get Running with Apache Flink on Kubernetes, part 1 of 2</title>
      <link>https://www.morling.dev/blog/get-running-with-apache-flink-on-kubernetes-1/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/get-running-with-apache-flink-on-kubernetes-1/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_installation_and_setup&#34;&gt;Installation and Setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_deployment_types&#34;&gt;Deployment Types&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_deploying_your_first_flink_job_on_kubernetes&#34;&gt;Deploying Your First Flink Job on Kubernetes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_building_custom_job_images&#34;&gt;Building Custom Job Images&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/get-running-with-apache-flink-on-kubernetes-1&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Kubernetes is a widely used deployment platform for Apache Flink.&#xA;While Flink has had native support for Kubernetes for quite a while, it is in particular the operator pattern which makes deploying Flink jobs onto Kubernetes clusters a compelling option: you define jobs in a declarative resource, and a control loop running in a component called a Kubernetes operator takes care of provisioning and maintaining (e.g.&#xA;scaling, updating) all the required resources.&#xA;Automation is the keyword here, significantly reducing the manual effort required for running Flink jobs in production.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>A Taxonomy Of Data Change Events</title>
      <link>https://www.morling.dev/blog/taxonomy-of-data-change-events/</link>
      <pubDate>Wed, 13 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/taxonomy-of-data-change-events/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_full_events&#34;&gt;Full Events&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_delta_events&#34;&gt;Delta Events&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_id_only_events&#34;&gt;Id-only Events&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_change_event_metadata&#34;&gt;Change Event Metadata&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_comparison&#34;&gt;Comparison&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/taxonomy-of-data-change-events&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Data change events are at the core of Change Data Capture (CDC) solutions such as &lt;a href=&#34;https://debezium.io/&#34;&gt;Debezium&lt;/a&gt;.&#xA;They describe the changes made to a specific record in a database and allow event consumers to take action based on this information, enabling a wide range of &lt;a href=&#34;https://www.morling.dev/blog/seven-ways-to-put-cdc-to-work&#34;&gt;use cases&lt;/a&gt;, such as real-time ETL (by propagating the updated data into downstream data stores such as data warehouses, analytics databases, or fulltext search indexes), microservices data exchange, or audit logging.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Getting Started With PyFlink on Kubernetes</title>
      <link>https://www.morling.dev/blog/getting-started-with-pyflink-on-kubernetes/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/getting-started-with-pyflink-on-kubernetes/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_what_is_pyflink_and_why_should_you_care&#34;&gt;What Is PyFlink and Why Should You Care?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&#xA;&lt;ul class=&#34;sectlevel2&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_installing_the_flink_kubernetes_operator&#34;&gt;Installing the Flink Kubernetes Operator&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_installing_strimzi_and_apache_kafka&#34;&gt;Installing Strimzi and Apache Kafka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_a_simple_pyflink_job&#34;&gt;A Simple PyFlink Job&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_building_a_container_image_with_your_pyflink_job&#34;&gt;Building a Container Image With Your PyFlink Job&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_deploying_a_pyflink_job_on_kubernetes&#34;&gt;Deploying a PyFlink Job On Kubernetes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/getting-started-with-pyflink-on-kubernetes&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;The other day, I wanted to get my feet wet with PyFlink.&#xA;While there is a fair amount of related information out there, I couldn’t find really up-to-date documentation on using current versions of PyFlink with Flink on Kubernetes.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>&#34;Change Data Capture Breaks Encapsulation&#34;. Does it, though?</title>
      <link>https://www.morling.dev/blog/change-data-capture-breaks-encapsulation-does-it-though/</link>
      <pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/change-data-capture-breaks-encapsulation-does-it-though/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_cdca_quick_primer&#34;&gt;CDC—​A Quick Primer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_does_cdc_break_encapsulation&#34;&gt;Does CDC Break Encapsulation?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_entering_data_contracts&#34;&gt;Entering Data Contracts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_implementation_approaches_for_data_contracts&#34;&gt;Implementation Approaches For Data Contracts&lt;/a&gt;&#xA;&lt;ul class=&#34;sectlevel2&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_the_outbox_pattern&#34;&gt;The Outbox Pattern&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_stream_processing&#34;&gt;Stream Processing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_streaming_data_contractsbeyond_the_basics&#34;&gt;Streaming Data Contracts—​Beyond the Basics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_handling_schema_changes&#34;&gt;Handling Schema Changes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/change-data-capture-breaks-encapsulation-does-it-though&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Having worked on Debezium—​an open-source platform for Change Data Capture (CDC)--for several years, one concern I’ve heard repeatedly is this: aren’t you breaking the encapsulation of your application when you expose change event feeds directly from your database?&#xA;After all, CDC exposes your internal persistent data model to the outside world, which may have unintended consequences, e.g.&#xA;in terms of data exposure but also when it comes to changes to the schema of your data, which may break downstream consumers.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>CDC Use Cases: 7 Ways to Put CDC to Work</title>
      <link>https://www.morling.dev/blog/cdc-use-cases/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://www.morling.dev/blog/cdc-use-cases/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_what_is_cdc&#34;&gt;What is CDC?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_cdc_tools&#34;&gt;CDC Tools&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_analytics_data_platforms&#34;&gt;Analytics Data Platforms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_application_caches&#34;&gt;Application Caches&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_full_text_search&#34;&gt;Full-Text Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_audit_logs&#34;&gt;Audit Logs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_continuous_queries&#34;&gt;Continuous Queries&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_microservices_data_exchange&#34;&gt;Microservices Data Exchange&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_monolith_to_microservices_migration&#34;&gt;Monolith-to-Microservices Migration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;&lt;em&gt;This post originally appeared on the &lt;a href=&#34;https://www.decodable.co/blog/cdc-use-cases&#34;&gt;Decodable blog&lt;/a&gt;. All rights reserved.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Change Data Capture (CDC) is a powerful tool in data engineering and has seen a tremendous uptake in organizations of all kinds over the last few years.&#xA;This is because it enables the tight integration of transactional databases into many other systems in your business at a very low latency.&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Why I Joined Decodable</title>
      <link>https://www.morling.dev/blog/why-i-joined-decodable/</link>
      <pubDate>Thu, 03 Nov 2022 15:00:00 +0100</pubDate>
      <guid>https://www.morling.dev/blog/why-i-joined-decodable/</guid>
      <description>Table of Contents The Space: Real-Time Stream Processing The Environment: A Start-up The Team: One of a Kind Outlook It’s my first week as a software engineer at Decodable, a start-up building a serverless real-time data platform! When I shared this news on social media yesterday, folks were not only super supportive and excited for me (thank you so much for all the nice words and wishes!), but some also asked about the reasons behind my decision for switching jobs and going to a start-up, after having worked for Red Hat for the last few years.</description>
    </item>
    <item>
      <title>Three Plus Some Lovely Kafka Trends</title>
      <link>https://www.morling.dev/blog/three-plus-some-lovely-kafka-trends/</link>
      <pubDate>Fri, 28 May 2021 10:30:00 +0200</pubDate>
      <guid>https://www.morling.dev/blog/three-plus-some-lovely-kafka-trends/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;&#xA;&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;&#xA;&lt;ul class=&#34;sectlevel1&#34;&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_cambrian_explosion_of_connectors&#34;&gt;Cambrian Explosion of Connectors&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_democratization_of_data_pipelines&#34;&gt;Democratization of Data Pipelines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_stream_processing_for_everyone&#34;&gt;Stream Processing for Everyone&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#_honorable_mentions&#34;&gt;Honorable Mentions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;Over the course of the last few months, I’ve had the pleasure to serve on the &lt;a href=&#34;https://www.kafka-summit.org/&#34;&gt;Kafka Summit&lt;/a&gt; program committee and review several hundred session abstracts for the three Summits happening this year (Europe, APAC, Americas).&#xA;That’s not only a big honour, but also a unique opportunity to learn what excites people currently in the Kafka eco-system&#xA;(and yes, it’s a fair amount of work, too ;).&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div class=&#34;paragraph&#34;&gt;&#xA;&lt;p&gt;While voting on the proposals, and also generally aspiring to stay informed of what’s going on in the Kafka community at large, I noticed a few repeating themes and topics which I thought would be interesting to share&#xA;(without touching on any specific talks of course).&#xA;At first I meant to put this out via a Twitter thread, but then it became a bit too long for that, so I decided to write this quick blog post instead.&#xA;Here it goes!&lt;/p&gt;&#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
