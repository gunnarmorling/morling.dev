<!DOCTYPE html>
<html>
<head>
	
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-DD997656SV"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-DD997656SV');
	</script>

	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Exploring ZooKeeper-less Kafka - Gunnar Morling</title>
	<link rel="icon" type="image/svg+xml" href="/favicon/favicon.svg" />
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png" />
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png" />
	<link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png" />
	<link rel="shortcut icon" href="/favicon/favicon.ico" />

	<meta name="viewport" content="width=device-width, initial-scale=1">

	
	<link rel="preload" href="/fonts/raleway-v37-latin-200.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/raleway-v37-latin-300.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/raleway-v37-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

	<link rel="preload" href="/fonts/lato-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lato-latin-400-italic.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lato-latin-700-normal.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lato-latin-700-italic.woff2" as="font" type="font/woff2" crossorigin>

	<link rel="preload" href="/fonts/lora-latin-400-normal.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lora-latin-400-italic.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lora-latin-700-normal.woff2" as="font" type="font/woff2" crossorigin>
	<link rel="preload" href="/fonts/lora-latin-700-italic.woff2" as="font" type="font/woff2" crossorigin><meta property="og:url" content="https://www.morling.dev/blog/exploring-zookeeper-less-kafka/">
  <meta property="og:site_name" content="Gunnar Morling">
  <meta property="og:title" content="Exploring ZooKeeper-less Kafka">
  <meta property="og:description" content=" Sometimes, less is more. One case where that’s certainly true is dependencies. And so it shouldn’t come at a surprise that the Apache Kafka community is eagerly awaiting the removal of the dependency …">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="blog">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2021-05-17T18:45:00&#43;01:00">
    <meta property="article:modified_time" content="2021-05-17T18:45:00&#43;01:00">
<meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Exploring ZooKeeper-less Kafka">
  <meta name="twitter:description" content=" Sometimes, less is more. One case where that’s certainly true is dependencies. And so it shouldn’t come at a surprise that the Apache Kafka community is eagerly awaiting the removal of the dependency …">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.min.efd5060e5dbdbc4655a896b01b99c2b759dc5710f5cfda5ed34c2259de325469.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/main.min.7e747dab5a47b967474cfdc64085734aa21b459c2bc3519033238d0258bb7dcc.css" />

	
	<link rel="stylesheet" type="text/css" href="/css/base16.dark.min.c40398d5ec04ac387c57141dc29e820fc4012da1cf2af8235004fc9945fa76a8.css" />
	
	<link rel="stylesheet" type="text/css" href="/css/morlingdev.min.20888cb6b76ed17eb07628f659718d130e32ea466294927dc4dfb410a3e3f3ab.css" />
	

	<script>
		const searchUrl = "https:\/\/search-morling-dev.onrender.com\/";
		const apiKey = "ff90d45f4afad3bd914c";
	</script>
	<script src="/js/main.min.9ee619eea7f51473f4284ef86c76bdb1b0089e19781ca97275924edf53be5bd4.js"></script>
	<script src="https://www.morling.dev//js/medium-zoom.min.js"></script>

	<noscript>
		<style type="text/css">
			.club { display:none; }
		</style>
	</noscript>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<div class="header-image-container">
		<img class="header-image" src="/images/gunnar_morling.jpg" alt="Gunnar Morling">
	</div>
	<div class="header-title">
		<h1 class="site-title"><a href="https://www.morling.dev/">Gunnar Morling</a></h1>
		<div class="site-description"><h2>Random Musings on All Things Software Engineering</h2></div>
	</div>
	<div class="header-nav-wrapper">
		<nav class="row pre-nav">
			<div class="pull-right">
				<ul class="flat"><li>
						<a href="/blog/index.xml" title="RSS FEED">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#rss"/>
							</svg>
						</a>
					</li><li>
						<a href="https://github.com/gunnarmorling" title="GitHub">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#github"/>
							</svg>
						</a>
					</li><li>
						<a href="https://bsky.app/profile/gunnarmorling.dev" title="Bluesky">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#cloud"/>
							</svg>
						</a>
					</li><li>
						<a href="https://twitter.com/gunnarmorling" title="Twitter">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#twitter"/>
							</svg>
						</a>
					</li><li>
						<a href="https://www.linkedin.com/in/gunnar-morling/" title="LinkedIn">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#linkedin"/>
							</svg>
						</a>
					</li><li>
						<a href="https://mastodon.online/@gunnarmorling" title="Mastodon">
							<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
								<use xlink:href="/svg/feather-sprite.svg#message-square"/>
							</svg>
						</a>
					</li></ul>
			</div>
		</nav>
		<nav class="row nav">
			<div>
				<ul class="flat">
					
					<li>
						<a href="/blog">Blog</a>
					</li>
					
					<li>
						<a href="/projects/">Projects</a>
					</li>
					
					<li>
						<a href="/conferences/">Conferences</a>
					</li>
					
					<li>
						<a href="/podcasts/">Podcasts</a>
					</li>
					
					<li>
						<a href="/about/">About</a>
					</li>
					
				</ul>
			</div>
			<div class="pull-right">
				<div class="club">
					<form id="myForm">
						<input type="text" id="inputSearch" name="q" placeholder="Search..." onfocus="warmUp(this)">
						<button type="submit" id="buttonSubmitSearch" style="line-height: normal;"><i id="iconSearch" class="fa fa-search"></i></button>
					</form>
				</div>
			</div>
		</nav>
	</div>
</div>

<script type="text/javascript">
	window.addEventListener( "load", function () {
		const form = document.getElementById( "myForm" );

		form.addEventListener("submit", function (event) {
			event.preventDefault();
			sendData(new FormData(form));
		});
	});
</script>


		<div id = "main-content">
			<div class="post-header">
				<h1 class="title">Exploring ZooKeeper-less Kafka</h1>
				<div class="post-meta-line">
					<span class="meta">Posted at May 17, 2021</span>
					
					<span class="post-tags-inline">
						
						<a href="/tags/kafka">kafka</a>
						
						<a href="/tags/kraft">kraft</a>
						
						<a href="/tags/architecture">architecture</a>
						
					</span>
					
				</div>
			</div>

			<div class="post-content">
				<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_trying_zk_less_kafka_yourself">Trying ZK-less Kafka Yourself</a></li>
<li><a href="#_taking_brokers_down">Taking Brokers Down</a></li>
<li><a href="#_wrap_up">Wrap-Up</a></li>
</ul>
</div>
<div class="paragraph">
<p>Sometimes, less is more.
One case where that’s certainly true is dependencies.
And so it shouldn’t come at a surprise that the <a href="https://kafka.apache.org/">Apache Kafka</a> community is eagerly awaiting the removal of the dependency to the <a href="https://zookeeper.apache.org/">ZooKeeper</a> service,
which currently is used for storing Kafka metadata (e.g. about topics and partitions) as well as for the purposes of leader election in the cluster.</p>
</div>
<div class="paragraph">
<p>The Kafka improvement proposal <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum">KIP-500</a>
(&#34;Replace ZooKeeper with a Self-Managed Metadata Quorum&#34;)
promises to make life better for users in many regards:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Better getting started and operational experience by requiring to run only one system, Kafka, instead of two</p>
</li>
<li>
<p>Removing potential for discrepancies of metadata state between ZooKeeper and the Kafka controller</p>
</li>
<li>
<p>Simplifying configuration, for instance when it comes to security</p>
</li>
<li>
<p>Better scalability, e.g. in terms of number of partitions; faster execution of operations like topic creation</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>With KIP-500, Kafka itself will store all the required metadata in an internal Kafka topic,
and controller election will be done amongst (a subset of) the Kafka cluster nodes themselves,
based on a variant of the <a href="https://raft.github.io/">Raft protocol</a> for distributed consensus.
Removing the ZooKeeper dependency is great not only for running Kafka clusters in production,
also for local development and testing being able to start up a Kafka node with a single process comes in very handy.</p>
</div>
<div class="paragraph">
<p>Having been in the works for multiple years, ZK-less Kafka,
also known as KRaft (&#34;Kafka Raft metadata mode&#34;), was recently published as an early access feature with <a href="https://blogs.apache.org/kafka/entry/what-s-new-in-apache5">Kafka 2.8</a>.
I.e. the perfect time to get my hands on this and get a first feeling for ZK-less Kafka myself.
Note this post isn’t meant to be a thorough evaluation or systematic testing of the new Kafka deployment mode,
rather take it as a description of how to get started with playing with ZK-less Kafka and of a few observations I made while doing so.</p>
</div>
<div class="paragraph">
<p>In the world of ZK-less Kafka, there’s two node roles for nodes: <em>controller</em> and <em>broker</em>.
Each node in the cluster can have either one or both roles (&#34;combined nodes&#34;).
All controller nodes elect the <em>active controller</em>,
which is in charge of coordinating the whole cluster,
with other controller nodes acting as hot stand-by replicas.
In the KRaft KIPs, the active controller sometimes also is simply referred to as <em>leader</em>.
This may appear confusing at first, if you are familiar with the existing concept of <em>partition leaders</em>.
It started to make sense to me once I realized that the active controller is the leader of the sole partition of the metadata topic.
All broker nodes are handling client requests, just as before with ZooKeeper.</p>
</div>
<div class="paragraph">
<p>While for smaller clusters it is expected that the majority of, or even all cluster nodes act as controllers,
you may have dedicated controller-only nodes in larger clusters,
e.g. 3 controller nodes and 7 broker nodes in a cluster of 10 nodes overall.
As per the <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md">KRaft README</a>,
having dedicated controller nodes should increase overall stability,
as for instance an out-of-memory error on a broker wouldn’t impact controllers, or potentially even cause a leader re-election.</p>
</div>
<div class="sect1">
<h2 id="_trying_zk_less_kafka_yourself">Trying ZK-less Kafka Yourself<a class="anchor" href="#_trying_zk_less_kafka_yourself"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>As a foundation,
I’ve <a href="https://github.com/gunnarmorling/docker-images/commit/cbd322d8a1f262be8bc48500f1a0776f835e6e3d">created a variant</a> of the Debezium 1.6 container image,
which updates Kafka from 2.7 to Kafka 2.8, and also does the required changes to the <a href="https://github.com/gunnarmorling/docker-images/blob/DBZ-3444/kafka/1.6/docker-entrypoint.sh">entrypoint script</a> for using the KRaft mode.
Note this change hasn’t been merged yet to the upstream Debezium repository,
so if you’d like to try out things by yourself, you’ll have to clone my repo, and then build the container image yourself like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="nv">$ </span>git clone git@github.com:gunnarmorling/docker-images.git
<span class="nv">$ </span><span class="nb">cd </span>docker-images/kafka/1.6
<span class="nv">$ </span>docker build <span class="nt">-t</span> debezium/zkless-kafka:1.6 <span class="nt">--build-arg</span> <span class="nv">DEBEZIUM_VERSION</span><span class="o">=</span>1.6.0 .
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In order to start the image with Kafka in KRaft mode, the <code>CLUSTER_ID</code> environment variable must be set.
A value can be obtained using the new <em>bin/kafka-storage.sh</em> script;
going forward, we’ll likely add an option to the Debezium Kafka container image for doing so.
If that variable is set,
the entrypoint script of the image does the following things:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use <em>config/kraft/server.properties</em> instead of <em>config/server.properties</em> as the Kafka configuration file;
this one comes with the Kafka distribution and is meant for nodes which should have both the controller and broker roles;
i.e. the container image currently only supports combined nodes</p>
</li>
<li>
<p><a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md#format-storage-directories">Format</a> the node’s storage directory, if not the case yet</p>
</li>
<li>
<p>Set up a listener for controller communication</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Based on that, here is what’s needed in a Docker Compose file for spinning up a Kafka cluster with three nodes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre></td><td class="code"><pre><span class="na">version</span><span class="pi">:</span> <span class="s1">&#39;</span><span class="s">2&#39;</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">kafka-1</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">debezium/zkless-kafka:1.6</span>
    <span class="na">ports</span><span class="pi">:</span>
     <span class="pi">-</span> <span class="s">19092:9092</span>
     <span class="pi">-</span> <span class="s">19093:9093</span>
    <span class="na">environment</span><span class="pi">:</span>
     <span class="pi">-</span> <span class="s">CLUSTER_ID=oh-sxaDRTcyAr6pFRbXyzA</span> <i class="conum" data-value="1"></i><b>(1)</b>
     <span class="pi">-</span> <span class="s">BROKER_ID=1</span> <i class="conum" data-value="2"></i><b>(2)</b>
     <span class="pi">-</span> <span class="s">KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093</span> <i class="conum" data-value="3"></i><b>(3)</b>
  <span class="na">kafka-2</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">debezium/zkless-kafka:1.6</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">29092:9092</span>
      <span class="pi">-</span> <span class="s">29093:9093</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">CLUSTER_ID=oh-sxaDRTcyAr6pFRbXyzA</span> <i class="conum" data-value="1"></i><b>(1)</b>
      <span class="pi">-</span> <span class="s">BROKER_ID=2</span> <i class="conum" data-value="2"></i><b>(2)</b>
      <span class="pi">-</span> <span class="s">KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093</span> <i class="conum" data-value="3"></i><b>(3)</b>
  <span class="na">kafka-3</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">debezium/zkless-kafka:1.6</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">39092:9092</span>
      <span class="pi">-</span> <span class="s">39093:9093</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">CLUSTER_ID=oh-sxaDRTcyAr6pFRbXyzA</span> <i class="conum" data-value="1"></i><b>(1)</b>
      <span class="pi">-</span> <span class="s">BROKER_ID=3</span> <i class="conum" data-value="2"></i><b>(2)</b>
      <span class="pi">-</span> <span class="s">KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093</span> <i class="conum" data-value="3"></i><b>(3)</b>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Cluster id; must be the <em>same</em> for all the nodes</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Broker id; must be <em>unique</em> for each node</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Addresses of all the controller nodes in the format <code>id1@host1:port1,id2@host2:port2…​</code></td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>No ZooKeeper nodes, yeah :)</p>
</div>
<div class="paragraph">
<p>Working on <a href="https://debezium.io/">Debezium</a>, and being a Kafka Connect aficionado allaround,
I’m also going to add Connect and a Postgres database for testing purposes
(you can find the complete Compose file <a href="https://github.com/gunnarmorling/debezium-examples/blob/zk-less-kafka/tutorial/docker-compose-zkless-kafka.yaml">here</a>):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="code"><pre><span class="na">version</span><span class="pi">:</span> <span class="s1">&#39;</span><span class="s">2&#39;</span>
<span class="na">services</span><span class="pi">:</span>

  <span class="c1"># ...</span>

  <span class="na">connect</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">debezium/connect:1.6</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">8083:8083</span>
    <span class="na">links</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">kafka-1</span>
      <span class="pi">-</span> <span class="s">kafka-2</span>
      <span class="pi">-</span> <span class="s">kafka-3</span>
      <span class="pi">-</span> <span class="s">postgres</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">BOOTSTRAP_SERVERS=kafka-1:9092</span>
      <span class="pi">-</span> <span class="s">GROUP_ID=1</span>
      <span class="pi">-</span> <span class="s">CONFIG_STORAGE_TOPIC=my_connect_configs</span>
      <span class="pi">-</span> <span class="s">OFFSET_STORAGE_TOPIC=my_connect_offsets</span>
      <span class="pi">-</span> <span class="s">STATUS_STORAGE_TOPIC=my_connect_statuses</span>
  <span class="na">postgres</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">debezium/example-postgres:1.6</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">5432:5432</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">POSTGRES_USER=postgres</span>
      <span class="pi">-</span> <span class="s">POSTGRES_PASSWORD=postgres</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now let’s start everything:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="nv">$ </span>docker-compose <span class="nt">-f</span> docker-compose-zkless-kafka.yaml up
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Let’s also register an instance of the Debezium Postgres connector,
which will connect to the PG database and take an initial snapshot,
so we got some topics with a few messages to play with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="code"><pre><span class="nv">$ </span>curl <span class="nt">-0</span> <span class="nt">-v</span> <span class="nt">-X</span> POST http://localhost:8083/connectors <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">&#34;Expect:&#34;</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s1">&#39;Content-Type: application/json; charset=utf-8&#39;</span> <span class="se">\</span>
  <span class="nt">--data-binary</span> @- <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh">
{
    &#34;name&#34;: &#34;inventory-connector&#34;,
    &#34;config&#34;: {
        &#34;connector.class&#34;: &#34;io.debezium.connector.postgresql.PostgresConnector&#34;,
        &#34;tasks.max&#34;: &#34;1&#34;,
        &#34;database.hostname&#34;: &#34;postgres&#34;,
        &#34;database.port&#34;: &#34;5432&#34;,
        &#34;database.user&#34;: &#34;postgres&#34;,
        &#34;database.password&#34;: &#34;postgres&#34;,
        &#34;database.dbname&#34; : &#34;postgres&#34;,
        &#34;database.server.name&#34;: &#34;dbserver1&#34;,
        &#34;schema.include&#34;: &#34;inventory&#34;,
        &#34;topic.creation.default.replication.factor&#34;: 2,
        &#34;topic.creation.default.partitions&#34;: 10
    }
}
EOF</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Note how this is using a replication factor of 2 for all the topics <a href="https://debezium.io/documentation/reference/configuration/topic-auto-create-config.html">created via Kafka Connect</a>,
which will come in handy for some experimenting later on.</p>
</div>
<div class="paragraph">
<p>The nosy person I am, I first wanted to take a look into that new internal metadata topic,
where all the cluster metadata is stored.
As per the <a href="https://blogs.apache.org/preview/kafka/?previewEntry=what-s-new-in-apache5">release announcement</a>,
it should be named <code>@metadata</code>.
But no such topic shows up when listing the available topics;
only the <code>__consumer_offsets</code> topic, the change data topics created by Debezium, and some Kafka Connect specific topics are shown:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
</pre></td><td class="code"><pre><span class="c"># Get a shell on one of the broker containers</span>
<span class="nv">$ </span>docker-compose <span class="nt">-f</span> docker-compose-zkless-kafka.yaml <span class="nb">exec </span>kafka-1 bash

<span class="c"># In that shell</span>
<span class="nv">$ </span>/kafka/bin/kafka-topics.sh <span class="nt">--bootstrap-server</span> kafka-3:9092  <span class="nt">--list</span>

__consumer_offsets
dbserver1.inventory.customers
dbserver1.inventory.geom
dbserver1.inventory.orders
dbserver1.inventory.products
dbserver1.inventory.products_on_hand
dbserver1.inventory.spatial_ref_sys
my_connect_configs
my_connect_offsets
my_connect_statuses
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Seems that this topic is truly meant to be internal;
also trying to consume messages from the topic with <em>kafka-console-consumer.sh</em> or <em>kafkacat</em> fails due to the invalid topic name.
Let’s see whether things are going to change here,
since <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A+A+Raft+Protocol+for+the+Metadata+Quorum">KIP-595</a>
(&#34;A Raft Protocol for the Metadata Quorum&#34;) explicitly mentions the ability for consumers to &#34;read the contents of the metadata log for debugging purposes&#34;.</p>
</div>
<div class="paragraph">
<p>In the meantime, we can take a look at the contents of the metadata topic using the <a href="https://jaceklaskowski.gitbooks.io/apache-kafka/content/kafka-tools-kafka-dump-log.html"><em>kafka-dump-log.sh</em></a> utility,
e.g. filtering out all <code>RegisterBroker</code> records:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="nv">$ </span>/kafka/bin/kafka-dump-log.sh <span class="nt">--cluster-metadata-decoder</span> <span class="se">\</span>
  <span class="nt">--skip-record-metadata</span> <span class="se">\</span>
  <span class="nt">--files</span> /kafka/data//<span class="se">\@</span>metadata-0/<span class="k">*</span>.log | <span class="nb">grep </span>REGISTER_BROKER

 payload: <span class="o">{</span><span class="s2">&#34;type&#34;</span>:<span class="s2">&#34;REGISTER_BROKER_RECORD&#34;</span>,<span class="s2">&#34;version&#34;</span>:0,<span class="s2">&#34;data&#34;</span>:<span class="o">{</span><span class="s2">&#34;brokerId&#34;</span>:3,<span class="s2">&#34;incarnationId&#34;</span>:<span class="s2">&#34;O_PiUrjNTsqVEQv61gB2Vg&#34;</span>,<span class="s2">&#34;brokerEpoch&#34;</span>:0,<span class="s2">&#34;endPoints&#34;</span>:[<span class="o">{</span><span class="s2">&#34;name&#34;</span>:<span class="s2">&#34;PLAINTEXT&#34;</span>,<span class="s2">&#34;host&#34;</span>:<span class="s2">&#34;172.18.0.2&#34;</span>,<span class="s2">&#34;port&#34;</span>:9092,<span class="s2">&#34;securityProtocol&#34;</span>:0<span class="o">}]</span>,<span class="s2">&#34;features&#34;</span>:[],<span class="s2">&#34;rack&#34;</span>:null<span class="o">}}</span>
 payload: <span class="o">{</span><span class="s2">&#34;type&#34;</span>:<span class="s2">&#34;REGISTER_BROKER_RECORD&#34;</span>,<span class="s2">&#34;version&#34;</span>:0,<span class="s2">&#34;data&#34;</span>:<span class="o">{</span><span class="s2">&#34;brokerId&#34;</span>:1,<span class="s2">&#34;incarnationId&#34;</span>:<span class="s2">&#34;FbOZdz9rSZqTyuSKr12JWg&#34;</span>,<span class="s2">&#34;brokerEpoch&#34;</span>:2,<span class="s2">&#34;endPoints&#34;</span>:[<span class="o">{</span><span class="s2">&#34;name&#34;</span>:<span class="s2">&#34;PLAINTEXT&#34;</span>,<span class="s2">&#34;host&#34;</span>:<span class="s2">&#34;172.18.0.3&#34;</span>,<span class="s2">&#34;port&#34;</span>:9092,<span class="s2">&#34;securityProtocol&#34;</span>:0<span class="o">}]</span>,<span class="s2">&#34;features&#34;</span>:[],<span class="s2">&#34;rack&#34;</span>:null<span class="o">}}</span>
 payload: <span class="o">{</span><span class="s2">&#34;type&#34;</span>:<span class="s2">&#34;REGISTER_BROKER_RECORD&#34;</span>,<span class="s2">&#34;version&#34;</span>:0,<span class="s2">&#34;data&#34;</span>:<span class="o">{</span><span class="s2">&#34;brokerId&#34;</span>:2,<span class="s2">&#34;incarnationId&#34;</span>:<span class="s2">&#34;ZF_WQqk_T5q3l1vhiWT_FA&#34;</span>,<span class="s2">&#34;brokerEpoch&#34;</span>:4,<span class="s2">&#34;endPoints&#34;</span>:[<span class="o">{</span><span class="s2">&#34;name&#34;</span>:<span class="s2">&#34;PLAINTEXT&#34;</span>,<span class="s2">&#34;host&#34;</span>:<span class="s2">&#34;172.18.0.4&#34;</span>,<span class="s2">&#34;port&#34;</span>:9092,<span class="s2">&#34;securityProtocol&#34;</span>:0<span class="o">}]</span>,<span class="s2">&#34;features&#34;</span>:[],<span class="s2">&#34;rack&#34;</span>:null<span class="o">}}</span>
 ...
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The individual record formats <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-631%3A+The+Quorum-based+Kafka+Controller#KIP631:TheQuorumbasedKafkaController-RecordFormats.1">are described</a> in KIP-631 (&#34;The Quorum-based Kafka Controller&#34;).</p>
</div>
<div class="paragraph">
<p>Another approach would be to use a brand-new tool, <em>kafka-metadata-shell.sh</em>.
Also defined in KIP-631,
this utility script allows to browse a cluster’s metadata,
similarly to <em>zookeeper-shell.sh</em> known from earlier releases.
For instance, you can list all brokers and get the metadata of the registration of node 1 like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
</pre></td><td class="code"><pre><span class="nv">$ </span>/kafka/bin/kafka-metadata-shell.sh <span class="nt">--snapshot</span> /kafka/data/@metadata-0/00000000000000000000.log

Loading...
Starting...
<span class="o">[</span> Kafka Metadata Shell <span class="o">]</span>
<span class="o">&gt;&gt;</span> <span class="nb">ls
</span>brokers  configs  <span class="nb">local  </span>metadataQuorum  topicIds  topics
<span class="o">&gt;&gt;</span> <span class="nb">ls </span>brokers
1  2  3
<span class="o">&gt;&gt;</span> <span class="nb">cd </span>brokers/1
<span class="o">&gt;&gt;</span> <span class="nb">cat </span>registration
RegisterBrokerRecord<span class="o">(</span><span class="nv">brokerId</span><span class="o">=</span>1, <span class="nv">incarnationId</span><span class="o">=</span>TmM_u-_cQ2ChbUy9NZ9wuA, <span class="nv">brokerEpoch</span><span class="o">=</span>265, <span class="nv">endPoints</span><span class="o">=[</span>BrokerEndpoint<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;PLAINTEXT&#39;</span>, <span class="nv">host</span><span class="o">=</span><span class="s1">&#39;172.18.0.3&#39;</span>, <span class="nv">port</span><span class="o">=</span>9092, <span class="nv">securityProtocol</span><span class="o">=</span>0<span class="o">)]</span>, <span class="nv">features</span><span class="o">=[]</span>, <span class="nv">rack</span><span class="o">=</span>null<span class="o">)</span>
<span class="o">&gt;&gt;</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Or to display the current leader:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="o">&gt;&gt;</span> <span class="nb">cat</span> /metadataQuorum/leader

MetaLogLeader<span class="o">(</span><span class="nv">nodeId</span><span class="o">=</span>1, <span class="nv">epoch</span><span class="o">=</span>12<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Or to show the metadata of a specific topic partition:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
</pre></td><td class="code"><pre><span class="o">&gt;&gt;</span> <span class="nb">cat</span> /topics/dbserver1.inventory.customers/0/data
<span class="o">{</span>
  <span class="s2">&#34;partitionId&#34;</span> : 0,
  <span class="s2">&#34;topicId&#34;</span> : <span class="s2">&#34;8xjqykVRT_WpkqbXHwbeCA&#34;</span>,
  <span class="s2">&#34;replicas&#34;</span> : <span class="o">[</span> 2, 3 <span class="o">]</span>,
  <span class="s2">&#34;isr&#34;</span> : <span class="o">[</span> 2, 3 <span class="o">]</span>,
  <span class="s2">&#34;removingReplicas&#34;</span> : null,
  <span class="s2">&#34;addingReplicas&#34;</span> : null,
  <span class="s2">&#34;leader&#34;</span> : 2,
  <span class="s2">&#34;leaderEpoch&#34;</span> : 0,
  <span class="s2">&#34;partitionEpoch&#34;</span> : 0
<span class="o">}</span>
<span class="o">&gt;&gt;</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Those are just a few of the things you can do with <em>kafka-metadata-shell.sh</em>,
and it surely will be an invaluable tool in the box of administrators in the ZK-less era.
Another new tool is <em>kafka-cluster.sh</em>, which currently can do two things:
displaying the unique id of a cluster, and unregistering a broker.
While the former worked for me:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="nv">$ </span>/kafka/bin/kafka-cluster.sh cluster-id <span class="nt">--bootstrap-server</span> kafka-1:9092

Cluster ID: oh-sxaDRTcyAr6pFRbXyzA
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The latter always failed with a <code>NotControllerException</code>, no matter on which node I invoked the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="nv">$ </span>/kafka/bin/kafka-cluster.sh unregister <span class="nt">--bootstrap-server</span> kafka-1:9092 <span class="nt">--id</span> 3

<span class="o">[</span>2021-05-15 20:52:54,626] ERROR <span class="o">[</span>AdminClient <span class="nv">clientId</span><span class="o">=</span>adminclient-1] Unregister broker request <span class="k">for </span>broker ID 3 failed: This is not the correct controller <span class="k">for </span>this cluster.
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>It’s not quite clear to me whether I did something wrong, or whether this functionality simply should not be expected to be supported just yet.</p>
</div>
<div class="paragraph">
<p>The Raft-based metadata quorum also comes with a set of new metrics (described in KIP-595),
allowing to retrieve information like the current active controller, role of the node at hand, and more.
Here’s a screenshot of the metrics invoked on a non-leader node:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/zookeeperless-kafka-metrics.png" alt="Kafka Raft Metrics in JDK Mission Control"/>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_taking_brokers_down">Taking Brokers Down<a class="anchor" href="#_taking_brokers_down"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>An essential aspect to any distributed system like Kafka is the fact that invidual nodes of a cluster can disappear at any time,
be it due to failures (node crashes, network splits, etc.), or due to controlled shut downs, e.g. for a version upgrade.
So I was curious how Kafka in KRaft mode would deal with the situation where nodes in the cluster are stopped and then restarted.
Note I’m stopping nodes gracefully via <em>docker-compose stop</em>, instead of randomly crashing them, Jepsen-style ;)</p>
</div>
<div class="paragraph">
<p>The sequence of events I was testing was the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Stop the current active controller, so two nodes from the original three-node cluster remain</p>
</li>
<li>
<p>Stop the then new active controller node, at which point the majority of cluster nodes isn’t available any longer</p>
</li>
<li>
<p>Start both nodes again</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Here’s a few noteworthy things I observed.
As you’d expect, when stopping the active controller, a new leader was elected (as per the result of <em>cat /metadataQuorum/leader</em> in the Kafka metadata shell),
and also all partitions which had the previous active controller as partition leader, got re-assigned
(in this case node <code>1</code> was the active controller and got stopped):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="code"><pre><span class="nv">$ </span>/kafka/bin/kafka-topics.sh <span class="nt">--bootstrap-server</span> kafka-2:9092 <span class="nt">--describe</span> <span class="nt">--topic</span> dbserver1.inventory.customers

Topic: dbserver1.inventory.customers	TopicId: a6qzjnQwQ2eLNSXL5svW8g	PartitionCount: 10	ReplicationFactor: 2	Configs: segment.bytes<span class="o">=</span>1073741824
	Topic: dbserver1.inventory.customers	Partition: 0	Leader: 1	Replicas: 1,3	Isr: 1,3
	Topic: dbserver1.inventory.customers	Partition: 1	Leader: 1	Replicas: 3,1	Isr: 1,3
	Topic: dbserver1.inventory.customers	Partition: 2	Leader: 1	Replicas: 1,2	Isr: 1,2
	Topic: dbserver1.inventory.customers	Partition: 3	Leader: 1	Replicas: 2,1	Isr: 1,2
	Topic: dbserver1.inventory.customers	Partition: 4	Leader: 1	Replicas: 2,1	Isr: 1,2
	Topic: dbserver1.inventory.customers	Partition: 5	Leader: 2	Replicas: 3,2	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 6	Leader: 2	Replicas: 3,2	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 7	Leader: 2	Replicas: 2,3	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 8	Leader: 1	Replicas: 2,1	Isr: 1,2
	Topic: dbserver1.inventory.customers	Partition: 9	Leader: 2	Replicas: 3,2	Isr: 2,3

<span class="c"># After stopping node 1</span>
<span class="nv">$ </span>/kafka/bin/kafka-topics.sh <span class="nt">--bootstrap-server</span> kafka-2:9092 <span class="nt">--describe</span> <span class="nt">--topic</span> dbserver1.inventory.customers

Topic: dbserver1.inventory.customers	TopicId: a6qzjnQwQ2eLNSXL5svW8g	PartitionCount: 10	ReplicationFactor: 2	Configs: segment.bytes<span class="o">=</span>1073741824
	Topic: dbserver1.inventory.customers	Partition: 0	Leader: 3	Replicas: 1,3	Isr: 3
	Topic: dbserver1.inventory.customers	Partition: 1	Leader: 3	Replicas: 3,1	Isr: 3
	Topic: dbserver1.inventory.customers	Partition: 2	Leader: 2	Replicas: 1,2	Isr: 2
	Topic: dbserver1.inventory.customers	Partition: 3	Leader: 2	Replicas: 2,1	Isr: 2
	Topic: dbserver1.inventory.customers	Partition: 4	Leader: 2	Replicas: 2,1	Isr: 2
	Topic: dbserver1.inventory.customers	Partition: 5	Leader: 2	Replicas: 3,2	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 6	Leader: 2	Replicas: 3,2	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 7	Leader: 2	Replicas: 2,3	Isr: 2,3
	Topic: dbserver1.inventory.customers	Partition: 8	Leader: 2	Replicas: 2,1	Isr: 2
	Topic: dbserver1.inventory.customers	Partition: 9	Leader: 2	Replicas: 3,2	Isr: 2,3
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Things got interesting though when also stopping the newly elected leader subsequently.
At this point, the cluster isn’t in a healthy state any longer,
as no majority of nodes of the cluster is available for leader election.
Logs of the remaining node are flooded with an <code>UnknownHostException</code> in this situation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="code"><pre>kafka-3_1   | 2021-05-16 10:16:45,282 - WARN  <span class="o">[</span>kafka-raft-outbound-request-thread:NetworkClient@992] - <span class="o">[</span>RaftManager <span class="nv">nodeId</span><span class="o">=</span>3] Error connecting to node kafka-2:9093 <span class="o">(</span><span class="nb">id</span>: 2 rack: null<span class="o">)</span>
kafka-3_1   | java.net.UnknownHostException: kafka-2
kafka-3_1   | 	at java.base/java.net.InetAddress<span class="nv">$CachedAddresses</span>.get<span class="o">(</span>InetAddress.java:797<span class="o">)</span>
kafka-3_1   | 	at java.base/java.net.InetAddress.getAllByName0<span class="o">(</span>InetAddress.java:1505<span class="o">)</span>
kafka-3_1   | 	at java.base/java.net.InetAddress.getAllByName<span class="o">(</span>InetAddress.java:1364<span class="o">)</span>
kafka-3_1   | 	at java.base/java.net.InetAddress.getAllByName<span class="o">(</span>InetAddress.java:1298<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.DefaultHostResolver.resolve<span class="o">(</span>DefaultHostResolver.java:27<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.ClientUtils.resolve<span class="o">(</span>ClientUtils.java:111<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.ClusterConnectionStates<span class="nv">$NodeConnectionState</span>.currentAddress<span class="o">(</span>ClusterConnectionStates.java:512<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.ClusterConnectionStates<span class="nv">$NodeConnectionState</span>.access<span class="nv">$200</span><span class="o">(</span>ClusterConnectionStates.java:466<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.ClusterConnectionStates.currentAddress<span class="o">(</span>ClusterConnectionStates.java:172<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.NetworkClient.initiateConnect<span class="o">(</span>NetworkClient.java:985<span class="o">)</span>
kafka-3_1   | 	at org.apache.kafka.clients.NetworkClient.ready<span class="o">(</span>NetworkClient.java:311<span class="o">)</span>
kafka-3_1   | 	at kafka.common.InterBrokerSendThread.<span class="nv">$anonfun$sendRequests$1</span><span class="o">(</span>InterBrokerSendThread.scala:103<span class="o">)</span>
kafka-3_1   | 	at kafka.common.InterBrokerSendThread.<span class="nv">$anonfun$sendRequests$1$adapted</span><span class="o">(</span>InterBrokerSendThread.scala:99<span class="o">)</span>
kafka-3_1   | 	at scala.collection.Iterator.foreach<span class="o">(</span>Iterator.scala:943<span class="o">)</span>
kafka-3_1   | 	at scala.collection.Iterator.foreach<span class="si">$(</span>Iterator.scala:943<span class="si">)</span>
kafka-3_1   | 	at scala.collection.AbstractIterator.foreach<span class="o">(</span>Iterator.scala:1431<span class="o">)</span>
kafka-3_1   | 	at scala.collection.IterableLike.foreach<span class="o">(</span>IterableLike.scala:74<span class="o">)</span>
kafka-3_1   | 	at scala.collection.IterableLike.foreach<span class="si">$(</span>IterableLike.scala:73<span class="si">)</span>
kafka-3_1   | 	at scala.collection.AbstractIterable.foreach<span class="o">(</span>Iterable.scala:56<span class="o">)</span>
kafka-3_1   | 	at kafka.common.InterBrokerSendThread.sendRequests<span class="o">(</span>InterBrokerSendThread.scala:99<span class="o">)</span>
kafka-3_1   | 	at kafka.common.InterBrokerSendThread.pollOnce<span class="o">(</span>InterBrokerSendThread.scala:73<span class="o">)</span>
kafka-3_1   | 	at kafka.common.InterBrokerSendThread.doWork<span class="o">(</span>InterBrokerSendThread.scala:94<span class="o">)</span>
kafka-3_1   | 	at kafka.utils.ShutdownableThread.run<span class="o">(</span>ShutdownableThread.scala:96<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here I think it’d be great to get a more explicit indication in the logs of what’s going on,
clearly indicating the unhealthy status of the cluster at large.</p>
</div>
<div class="paragraph">
<p>What’s also interesting is that the remaining node claims to be a leader as per its exposed metrics and value of <code>/metadataQuorum/leader</code> in the metadata shell.
This seems a bit dubious, as no leader election can happen without the majority of nodes available.
Consequently, creation of a topic in this state also times out,
so I suspect this is more an artifact of displaying the cluster state rather than of what’s actually going on.</p>
</div>
<div class="paragraph">
<p>Things get a bit more troublesome when restarting the two stopped nodes;
Very often I’d then see a very high CPU consumption on the Kafka nodes as well as the Connect node:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="bash"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="nv">$ </span>docker stats

CONTAINER ID   NAME                  CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O       PIDS
642eb697fed6   tutorial_connect_1    122.04%   668.3MiB / 7.775GiB   8.39%     99.7MB / 46.9MB   131kB / 106kB   47
5d9806526f92   tutorial_kafka-1_1    9.24%     386.4MiB / 7.775GiB   4.85%     105kB / 104kB     0B / 877kB      93
767e6c0f6cd3   tutorial_kafka-3_1    176.40%   739.2MiB / 7.775GiB   9.28%     14.5MB / 40.6MB   0B / 1.52MB     120
a0ce8438557f   tutorial_kafka-2_1    87.51%    567.8MiB / 7.775GiB   7.13%     6.52MB / 24.9MB   0B / 881kB      95
df978d220132   tutorial_postgres_1   0.00%     36.39MiB / 7.775GiB   0.46%     243kB / 5.49MB    0B / 79.4MB     9
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>In some cases stopping and restarting the Kafka nodes would help,
other times only a restart of the Connect node would mitigate the situation.
I didn’t further explore this issue by taking a thread dump,
but I suppose threads are stuck in some kind of busy spin loop at this point.
The early access state of KRaft mode seems to be somewhat showing here.
After <a href="https://lists.apache.org/thread.html/r411d22fb8c092de0693eda10f0f0f383ff15fd60d3624ad57b6c2a2a%40%3Cdev.kafka.apache.org%3E">bringing up</a> the issue on the Kafka mailing list,
I’ve logged <a href="https://issues.apache.org/jira/browse/KAFKA-12801">KAFKA-12801</a> for this problem,
as it seems not to have been tracked before.</p>
</div>
<div class="paragraph">
<p>On the bright side, once all brokers were up and running again,
the cluster and the Debezium connector would happily continue their work.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_wrap_up">Wrap-Up<a class="anchor" href="#_wrap_up"></a></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Not many features have been awaited by the Kafka community as eagerly as the removal of the ZooKeeper dependency.
Rightly so: Kafka-based metadata storage and leader election will greatly simplify the operational burden for running Kafka and also allow for better scalability.
Lifting the requirement for running separate ZooKeeper processes or even machines should also help to make things more cost-effective,
so you should benefit from this change no matter whether you’re running Kafka yourself or are using a managed service offering.</p>
</div>
<div class="paragraph">
<p>The early access release of ZK-less Kafka in version 2.8 gives a first impression of what will hopefully be the standard way of running Kafka in the not too distant future.
As very clearly stated in the <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md#missing-features">KRaft README</a>,
you should not use this in production yet;
this matches with the observerations made above:
while running Kafka without ZooKeeper definitely feels great,
there’s still some rough edges to be sorted out.
Also check out the README for a list of currently <a href="https://github.com/apache/kafka/blob/trunk/config/kraft/README.md#missing-features">missing features</a>,
such as support of transactions, adding partitions to existing topics, partition reassignment, and more.
Lastly, any distributed system should only be fully trusted after going through the grinder of the <a href="https://jepsen.io/">Jepsen</a> test suite,
which I’m sure will only be a question of time.</p>
</div>
<div class="paragraph">
<p>Despite the early state, I would very much recommend to get started testing ZK-less Kafka at this point,
so to get a feeling for it and of course to report back any findings and insights.
To do so, either download the <a href="https://kafka.apache.org/downloads">upstream Kafka distribution</a>,
or build the Debezium 1.6 container image for Kafka with preliminary <a href="https://github.com/gunnarmorling/docker-images/tree/DBZ-3444/kafka/1.6">support for KRaft mode</a>,
which lets you set up a ZK-less Kafka cluster in no time.</p>
</div>
<div class="paragraph">
<p>In order to learn more about ZK-less Kafka, besides diving into the relevant KIPs (which all are linked from the umbrella KIP-500),
also check out the QCon talk <a href="https://www.infoq.com/presentations/kafka-zookeeper/">&#34;Kafka Needs No Keeper&#34;</a> by Colin McCabe, one of the main engineers driving this effort.</p>
</div>
</div>
</div>
			</div>

			
			
			
			<div class="related-posts">
				<h3>Read Next</h3>
				<ul>
					
					<li><a href="/blog/you-dont-need-kafka-just-use-postgres-considered-harmful/">&#34;You Don&#39;t Need Kafka, Just Use Postgres&#34; Considered Harmful</a> <span class="meta">Nov 3, 2025</span></li>
					
					<li><a href="/blog/what-if-we-could-rebuild-kafka-from-scratch/">What If We Could Rebuild Kafka From Scratch?</a> <span class="meta">Apr 24, 2025</span></li>
					
					<li><a href="/blog/announcing-first-release-of-kcctl/">Announcing the First Release of kcctl</a> <span class="meta">Dec 21, 2021</span></li>
					
				</ul>
			</div>
			
			
		</div>

		<div class="post-footer">
			<div style="display: flex; align-items: center; gap: 1rem;">
				<div class="header-image-container" style="flex-shrink: 0;">
					<img class="footer-image" src="/images/gunnar_morling.jpg" alt="Gunnar Morling">
				</div>
				<p style="margin: 0;">Gunnar Morling is an open-source software engineer in the Java and data streaming space. He currently works as a Technologist for Confluent. In his past role at Decodable he focused on developer outreach and helped them build their stream processing platform based on Apache Flink. Prior to that, he spent ten years at Red Hat, where he led the Debezium project, a platform for change data capture.</p>
			</div>
		</div>

		
		
		<div class="post-discussions">
			<p>Comment below, or join the discussion on
			<a href="https://hn.algolia.com/?query=morling.dev/blog/exploring-zookeeper-less-kafka/">Hacker News</a>,
			<a href="https://lobste.rs/search?q=domain:morling.dev+title:%22Exploring%20ZooKeeper-less%20Kafka%22&what=stories">Lobsters</a>, and
			<a href="https://www.reddit.com/search/?q=url:morling.dev/blog/exploring-zookeeper-less-kafka/">Reddit</a>.
			</p>
		</div>
		<div id="disqus_thread"></div>

<script>
  
  window.addEventListener('load', function() {
    
    setTimeout(function() {
      const commentsContainer = document.getElementById('disqus_thread');
      const script = document.createElement('script');
      script.src = 'https://giscus.app/client.js';
      script.setAttribute('data-repo', 'gunnarmorling/discussions.morling.dev');
      script.setAttribute('data-repo-id', 'R_kgDOGXzqNQ');
      script.setAttribute('data-category', 'Announcements');
      script.setAttribute('data-category-id', 'DIC_kwDOGXzqNc4B_2Pq');
      script.setAttribute('data-mapping', 'title');
      script.setAttribute('data-reactions-enabled', '1');
      script.setAttribute('data-emit-metadata', '0');
      script.setAttribute('data-theme', 'light');
      script.setAttribute('data-lang', 'en');
      script.setAttribute('crossorigin', 'anonymous');
      script.async = true;
      commentsContainer.appendChild(script);
    }, 100);
  });
</script>

<noscript>Please enable JavaScript, or join the <a href="https://github.com/gunnarmorling/discussions.morling.dev/discussions/">discussion on GitHub</a>.</noscript>
</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> © 2019 - 2026 Gunnar Morling |  Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons BY-SA 4.0</a> | <a href="/ai">How I use (and don't use) AI</a></div>
	</nav>
</div><script>
	mediumZoom(document.querySelectorAll('div.imageblock > div.content > img'))
</script>

</body>
</html>
