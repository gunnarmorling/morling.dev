<!DOCTYPE html>
<html>
<head>
	
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-DD997656SV"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-DD997656SV');
	</script>

	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>An Ideation for Kubernetes-native Kafka Connect - Gunnar Morling</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="An Ideation for Kubernetes-native Kafka Connect" />
<meta property="og:description" content="Kafka Connect, part of the Apache Kafka project, is a development framework and runtime for connectors which either ingest data into Kafka clusters (source connectors) or propagate data from Kafka into external systems (sink connectors). A diverse ecosystem of ready-made connectors has come to life on top of Kafka Connect, which lets you connect all kinds of data stores, APIs, and other systems to Kafka in a no-code approach." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.morling.dev/blog/ideation-kubernetes-native-kafka-connect/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2022-09-06T14:20:00+01:00" />
<meta property="article:modified_time" content="2022-09-06T14:20:00+01:00" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="An Ideation for Kubernetes-native Kafka Connect"/>
<meta name="twitter:description" content="Kafka Connect, part of the Apache Kafka project, is a development framework and runtime for connectors which either ingest data into Kafka clusters (source connectors) or propagate data from Kafka into external systems (sink connectors). A diverse ecosystem of ready-made connectors has come to life on top of Kafka Connect, which lets you connect all kinds of data stores, APIs, and other systems to Kafka in a no-code approach."/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet" />
	<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" />
 
	<link rel="stylesheet" type="text/css" media="screen" href="https://www.morling.dev/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://www.morling.dev/css/main.css" />

	
	<link rel="stylesheet" type="text/css" href="https://www.morling.dev/css/base16.dark.css" />
	
	<link rel="stylesheet" type="text/css" href="https://www.morling.dev/css/morlingdev.css" />
	

	<script>
		const searchUrl = "https:\/\/search-morling-dev.onrender.com\/";
		const apiKey = "ff90d45f4afad3bd914c";
	</script>

	<script src="https://www.morling.dev//js/main.js"></script>
	<script src="https://www.morling.dev//js/medium-zoom.min.js"></script>

	<noscript>
		<style type="text/css">
			.club { display:none; }
		</style>
	</noscript>
</head>

<body>
	<div class="container wrapper post">
		<div class="header desktop">

	<div class="row">
		<div class="header-image-container">
			<img class="header-image" src="/images/gunnar_morling.jpg" alt="Gunnar Morling">
		</div>
		<div class="fill">
			<h1 class="site-title"><a href="https://www.morling.dev/">Gunnar Morling</a></h1>
			<div class="site-description"><h2>Random Musings on All Things Software Engineering</h2></div>

			<nav class="row pre-nav">
				<div class="pull-right">
					<ul class="flat"><li>
							<a href="/blog/index.xml" title="RSS FEED">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#rss"/>
								</svg>
							</a>
						</li><li>
							<a href="https://github.com/gunnarmorling" title="GitHub">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#github"/>
								</svg>
							</a>
						</li><li>
							<a href="https://bsky.app/profile/gunnarmorling.dev" title="Bluesky">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#cloud"/>
								</svg>
							</a>
						</li><li>
							<a href="https://twitter.com/gunnarmorling" title="Twitter">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#twitter"/>
								</svg>
							</a>
						</li><li>
							<a href="https://www.linkedin.com/in/gunnar-morling/" title="LinkedIn">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#linkedin"/>
								</svg>
							</a>
						</li><li>
							<a href="https://mastodon.online/@gunnarmorling" title="Mastodon">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#message-square"/>
								</svg>
							</a>
						</li></ul>
				</div>
			</nav>
			<nav class="row nav">
				<div>
					<ul class="flat">
						
						<li>
							<a href="/">Blog</a>
						</li>
						
						<li>
							<a href="/projects/">Projects</a>
						</li>
						
						<li>
							<a href="/conferences/">Conferences</a>
						</li>
						
						<li>
							<a href="/podcasts/">Podcasts</a>
						</li>
						
						<li>
							<a href="/about/">About</a>
						</li>
						
					</ul>
				</div>
				<div class="pull-right">
					<div class="club">
						<form id="myForm">
							<input type="text" id="inputSearch" name="q" placeholder="Search..." onfocus="warmUp(this)">
							<button type="submit" id="buttonSubmitSearch" style="line-height: normal;"><i id="iconSearch" class="fa fa-search"></i></button>
						</form>
					</div>
				</div>
			</nav>
		</div>
	</div>
</div>

<div class="header mobile">

	<div class="row">
		<div class="header-image-container">
			<img class="header-image" src="/images/gunnar_morling.jpg" alt="Gunnar Morling">
		</div>
		<div class="fill">
			<h1 class="site-title"><a href="https://www.morling.dev/">Gunnar Morling</a></h1>
			<div class="site-description"><h2>Random Musings on All Things Software Engineering</h2></div>
		</div>
	</div>
	<div>
		<div>
			<nav class="row pre-nav">
				<div class="pull-right">
					<ul class="flat"><li>
							<a href="/blog/index.xml" title="RSS FEED">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#rss"/>
								</svg>
							</a>
						</li><li>
							<a href="https://github.com/gunnarmorling" title="GitHub">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#github"/>
								</svg>
							</a>
						</li><li>
							<a href="https://bsky.app/profile/gunnarmorling.dev" title="Bluesky">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#cloud"/>
								</svg>
							</a>
						</li><li>
							<a href="https://twitter.com/gunnarmorling" title="Twitter">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#twitter"/>
								</svg>
							</a>
						</li><li>
							<a href="https://www.linkedin.com/in/gunnar-morling/" title="LinkedIn">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#linkedin"/>
								</svg>
							</a>
						</li><li>
							<a href="https://mastodon.online/@gunnarmorling" title="Mastodon">
								<svg width="17" height="17" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
									<use xlink:href="/svg/feather-sprite.svg#message-square"/>
								</svg>
							</a>
						</li></ul>
				</div>
			</nav>
			<nav class="row nav">
				<div>
					<ul class="flat">
						
						<li>
							<a href="/">Blog</a>
						</li>
						
						<li>
							<a href="/projects/">Projects</a>
						</li>
						
						<li>
							<a href="/conferences/">Conferences</a>
						</li>
						
						<li>
							<a href="/podcasts/">Podcasts</a>
						</li>
						
						<li>
							<a href="/about/">About</a>
						</li>
						
					</ul>
				</div>
				<div class="pull-right">
					<div class="club">
						<form id="myFormMobile">
							<input type="text" id="inputSearchMobile" name="q" placeholder="Search..." onfocus="warmUp(this)">
							<button type="submit" id="buttonSubmitSearchMobile" style="line-height: normal;"><i id="iconSearchMobile" class="fa fa-search"></i></button>
						</form>
					</div>
				</div>
			</nav>
		</div>
	</div>
</div>

<script type="text/javascript">
	window.addEventListener( "load", function () {
		const urlParams = new URLSearchParams(window.location.search);

		


		const form = document.getElementById( "myForm" );

		form.addEventListener("submit", function (event) {
			event.preventDefault();
			sendData(new FormData(form));
		});

		const formMobile = document.getElementById( "myFormMobile" );

		formMobile.addEventListener("submit", function (event) {
			event.preventDefault();
			sendData(new FormData(formMobile));
		});
	});
</script>


		<div id = "main-content">
			<div class="post-header">
				<h1 class="title">An Ideation for Kubernetes-native Kafka Connect</h1>
				<div class="meta">Posted at Sep 6, 2022</div>
			</div>

			<div class="markdown">
				<div class="paragraph">
<p><a href="https://kafka.apache.org/documentation/#connect">Kafka Connect</a>, part of the Apache Kafka project, is a development framework and runtime for connectors which either ingest data into Kafka clusters (<em>source connectors</em>) or propagate data from Kafka into external systems (<em>sink connectors</em>). A diverse ecosystem of ready-made connectors has come to life on top of Kafka Connect, which lets you connect all kinds of data stores, APIs, and other systems to Kafka in a no-code approach.</p>
</div>
<div class="paragraph">
<p>With the continued move towards running software in the cloud and on Kubernetes in particular, it’s just natural that many folks also try to run Kafka Connect on Kubernetes. On first thought, this should be simple enough: just take the Connect binary and some connector(s), put them into a container image, and schedule it for execution on Kubernetes. As so often, the devil is in the details though: should you use Connect’s standalone or distributed mode? How can you control the lifecycle of specific connectors via the Kubernetes control plane? How to make sure different connectors don’t compete unfairly on resources such as CPU, RAM, or network bandwidth? In the remainder of this blog post, I’d like to explore running Kafka Connect on Kubernetes, what some of the challenges are for doing so, and how Kafka Connect could potentially be reimagined to become more &#34;Kubernetes-friendly&#34; in the future.</p>
</div>
<div class="sect1">
<h2 id="_standalone_or_distributed">Standalone or Distributed?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>If you’ve used Kafka Connect before, then you’ll know that it has <a href="https://kafka.apache.org/documentation/#connect_running">two modes of execution</a>: standalone and distributed. In the former, you configure Connect via property files which you pass as parameters during launch. There will be a single process which executes all the configured connectors and their tasks. In distributed mode, multiple Kafka Connect worker nodes running on different machines form a cluster onto which the workload of the connectors and their tasks is distributed. Configuration is done via a REST API which is exposed on all the worker nodes. Internally, A Connect-specific protocol (which itself is based on Kafka’s <a href="https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2">group membership protocol</a>) is used for the purposes of coordination and task assignment.</p>
</div>
<div class="paragraph">
<p>The distributed mode is in general the preferred and recommended mode of operating Connect in production, due to its obvious advantages in regards to scalability (one connector can spawn many tasks which are executed on different machines), reliability (connector configuration and offset state is stored in Kafka topics rather than files in the local file system), and fault tolerance (if one worker node crashes, the tasks which were scheduled on that node can be transparently rebalanced to other members of the Connect cluster).</p>
</div>
<div class="paragraph">
<p>That’s why also Kafka users on Kubernetes typically opt for Connect’s distributed mode, as for instance it’s the case with Strimzi’s <a href="https://strimzi.io/docs/operators/latest/overview.html#configuration-points-connect_str">operator for Kafka Connect</a>. But that’s not without its issues either, as now essentially two scheduling systems are competing with each other: Kubernetes itself (scheduling pods to compute nodes), and Connect’s worker coordination mechanism (scheduling connector tasks to Connect worker nodes). This becomes particularly apparent in case of node failures. Should the Kubernetes scheduler spin up the affected pods on another node in the Kubernetes cluster, or should you rely on Connect to schedule the affected tasks to another Connect worker node? Granted, improvements in this area have been made, for instance in form of Kafka improvement proposal <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-415%3A+Incremental+Cooperative+Rebalancing+in+Kafka+Connect">KIP-415</a> (&#34;Incremental Cooperative Rebalancing in Kafka Connect&#34;). It adds a new configuration property <code>scheduled.rebalance.max.delay.ms</code>, allowing you to defer rebalances after worker failures. But such a setting will always be a trade-off, and I think in general it’s fair to say that if there’s multiple components in a system which share the same responsibility (placement of workloads), that’s likely going to be a friction point.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_issues_with_kafka_connect_on_kubernetes">Issues with Kafka Connect on Kubernetes</h2>
<div class="sectionbody">
<div class="paragraph">
<p>So let’s explore a bit more the challenges users often encounter when running Kafka Connect on Kubernetes. One general problem is the lack of awareness for running on Kubernetes from a Connect perspective.</p>
</div>
<div class="paragraph">
<p>For instance, consider the case of a <a href="https://kubernetes.io/docs/setup/best-practices/multiple-zones/">stretched Kubernetes cluster</a>, with Kubernetes nodes running in different regions of a cloud provider, or within different data centers. Let’s assume you have a source connector which ingests data from a database running within one of the regions. As you’re only interested in a subset of the records produced by that connector, you use a Kafka Connect <a href="/blog/single-message-transforms-swiss-army-knife-of-kafka-connect/">single message transformation</a> for filtering out a significant number of records. In that scenario, it makes sense to deploy that connector in local proximity to the database it connects to, so as to limit the data that’s transferred across network boundaries. But Kafka Connect doesn’t have any understanding of &#34;regions&#34; or related Kubernetes concepts like <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector">node selectors</a> or node pools, i.e. you’ll lack the control needed for making sure that the tasks of that connector get scheduled onto Connect worker nodes running on the right Kubernetes nodes (a mitigation strategy would be to set up multiple Connect clusters, tied to specific Kubernetes node pools in the different regions).</p>
</div>
<div class="paragraph">
<p>A second big source of issues is Connect’s model for the deployment of connectors, which in a way resembles the approach taken by Java application servers in the past: multiple, independent connectors are deployed and executed in shared JVM processes. This results in a lack of isolation between connectors, which can have far-reaching consequences in production scenarios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Connectors compete on resources:</em> one connector or task can use up an unfairly large share of CPU, RAM or networking resources assigned to a pod, so that other connectors running on the same Connect worker will be negatively impacted; this could be caused by bugs or poor programming, but it also can simply be a result of different workload requirements, with one connector requiring more resources than others. While a rate limiting feature for Connect is being proposed via <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-731%3A+Record+Rate+Limiting+for+Kafka+Connect">KIP-731</a> (which may eventually address the issue of distributing network resources more fairly), there’s no satisfying answer for assigning and limiting CPU and RAM resources when running multiple connectors on one shared JVM, due to its lack of application isolation.</p>
</li>
<li>
<p><em>Scaling complexities:</em> when increasing the number of tasks of a connector (so as to scale out its load), it’s likely also necessary to increase the number of Connect workers, unless there were idle workers before; this process seems more complex and at  the same time less powerful than it should be. For instance, there’s no way for ensuring that additional worker nodes would exclusively be used for the tasks of one particularly demanding connector.</p>
</li>
<li>
<p><em>Security implications:</em> as per the OpenJDK Vulnerability Group, &#34;speculative execution vulnerabilities (e.g., Meltdown, Spectre, and RowHammer) <a href="https://mail.openjdk.org/pipermail/vuln-announce/2019-July/000002.html">cannot be addressed in the JDK</a>. These hardware design flaws make complete intra-process isolation impossible&#34;. Malicious connectors could leverage these attack vectors for instance to obtain secrets from other connectors running on the same JVM. Furthermore, some connectors rely on secrets (such as cloud SDK credentials) to be provided in the form of environment variables or Java system properties, which by definition are accessible by all connectors scheduled on the same Connect worker node.</p>
</li>
<li>
<p><em>Risk of resource leaks</em> <em>:</em> Incorrectly implemented connectors can cause memory and thread leaks after they were stopped, resulting in out-of-memory errors after stopping and restarting them several times, potentially impacting other connectors and tasks running on the same Connect worker node.</p>
</li>
<li>
<p><em>Can’t use Kubernetes health checks:</em> as health checks (such as <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">liveness probes</a>) work on the container level, a failed health check would restart the container, and thus Connect worker node with all its connectors, even if only one connector is actually failing. On the other hand, when relying on Connect itself to restart failed connectors and/or tasks, that’s not visible at the level of the Kubernetes control plane, resulting potentially in a false impression of a good health status of a connector, while it actually is in a restarting loop.</p>
</li>
<li>
<p><em>Can’t easily examine logs of a single connector:</em> When examining the logs of a Kafka Connect pod, messages from multiple running connectors will potentially show up in an interweaved way, depending on the specific logger configurations; as log messages can be prefixed with the connector name, that’s not that much of an issue when analyzing logs in dedicated tools like Logstash or Splunk, but it can be challenging when looking at the raw pod logs on the command line or via a Kubernetes web console.</p>
</li>
<li>
<p><em>Can’t run multiple versions of one connector:</em> As connectors are solely identified by their classname, it’s not possible to set up a connector instance of a specific version in case there’s multiple versions of that connector present.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Lastly, a third category of issues with running Connect on Kubernetes stems from the inherently mutable design of the system and the ability to dynamically instantiate and reconfigure connectors at runtime via a REST API.</p>
</div>
<div class="paragraph">
<p>Without proper discipline, this can quickly lead to a lack of insight into the connector configuration applying at a given time (in Strimzi, this is solved by preferrably deploying connectors via <a href="https://strimzi.io/blog/2020/01/27/deploying-debezium-with-kafkaconnector-resource/">custom Kubernetes resources</a>, rather than invoking the REST API directly). In fact, the REST API itself can be a source of issues: access to it needs to be secured in production use cases, also I’ve come across multiple reports over the years (and witnessed myself) where the REST API became unresponsive, while Connect itself still was running. It’s not exactly clear why this happened, but one potential course could be a buggy connector, consuming 100% of CPU cycles, leaving not enough resources for the REST API worker threads. Essentially, I think that such a control plane element like a REST API shouldn’t really be exposed on each member of a data plane, as represented by Connect worker nodes.</p>
</div>
<div class="paragraph">
<p>Based on all these challenges, in particular those around lacking isolation between different connectors, many users of Kafka Connect stick to the practice of actually not deploying multiple connectors into shared worker clusters, but instead operate a dedicated cluster of Kafka Connect for each connector. This could be a cluster with a node count equal to the configured number of tasks, essentially resulting in 1:1 mapping of tasks to worker processes. Some users also deploy a number of spare workers for fail-over purposes. In fact, that’s the recommendation we’ve been giving to users in the Debezium community for a long time, and it also tends to be a common choice amongst providers of managed Kafka Connect services. Another approach taken by <a href="https://www.confluent.io/events/kafka-summit-americas-2021/connect-at-twitter-scale/">some teams</a> is to deploy specific Connect clusters per <em>connector type</em> , preventing interferences between different kinds of connectors.</p>
</div>
<div class="paragraph">
<p>All these strategies can help to run connectors for running connectors safely and reliably, but the operational overhead of running multiple Connect clusters is evident.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_a_vision_for_kubernetes_native_kafka_connect">A Vision for Kubernetes-native Kafka Connect</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Having explored the potential issues with running Kafka Connect on Kubernetes, let’s finally discuss how Connect could be reimagined for being more Kubernetes-friendly. What are the parts that could remain? Which things would have to change? Many of the questions and shortcomings raised above – such as workload isolation, applying resource constraints, capability-based scheduling, lifecycle management – have been solved by Kubernetes at the pod level already, so how could that foundation be leveraged for Kafka Connect?</p>
</div>
<div class="paragraph">
<p>To put a disclaimer first: this part of this post may be a bit dissatisfying to read for some, as it merely describes an <em>idea</em>, I haven’t actually implemented any of this. My line of thinking is to hopefully ignite a discussion in the community and gauge the general level of interest, perhaps even motivating someone in the community to follow through and make this a reality. At least, that’s the plan :)</p>
</div>
<div class="paragraph">
<p>The general idea is to keep all the actual runtime bits and pieces of Connect: that’s key to being able to run all the amazing existing connectors out there, which are implemented against Connect’s framework interfaces. All the semantics and behaviors, like converters and SMTs, retries, dead-letter queue support, the upcoming exactly-once support for source connectors (<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-618%3A+Exactly-Once+Support+for+Source+Connectors">KIP-618</a>), all that could just be used as is.</p>
</div>
<div class="paragraph">
<p>But the entire layer for forming and coordinating clusters of worker nodes and distributing tasks amongst them would be replaced by a <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Kubernetes <em>operator</em></a>. To quote the official docs, &#34;operators are software extensions to Kubernetes that make use of <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">custom resources</a> to manage applications and their components. Operators follow Kubernetes principles, notably the <a href="https://kubernetes.io/docs/concepts/architecture/controller">control loop</a>&#34;.
The overall architecture would look like this:</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="/images/kafka_connect_operator.png" alt="Proposed Architecture for Kubernetes-native Kafka Connect"/></span></p>
</div>
<div class="paragraph">
<p>In this envisioned model for Kafka Connect, such an operator <i class="conum" data-value="1"></i> would spin up one separate Kubernetes pod (and thus JVM process) for each connector task <i class="conum" data-value="2"></i> of a connector. Conceptually, those task processes would be somewhat of a mixture between today’s Connect standalone and distributed modes. Like standalone mode in the sense, that there would be no coordination amongst worker nodes and also no capability to dynamically reconfigure or start and stop a running task; each process/pod would run exactly one task in isolation, coordinated by the operator. Similar to distributed mode in the sense, that there would be a read-only REST API for health information, and that connector offsets would be stored in a Kafka topic, so as to avoid any pod-local state. There wouldn’t be the need for the configuration topic though, as the configuration would be passed upon start-up to the task pods (again akin to standalone mode today, e.g. by mapping a properties file to the pod), with the custom Kubernetes resources defining the connectors being the &#34;system of record&#34; for their configuration.</p>
</div>
<div class="paragraph">
<p>For this to work, the connector configuration needs to be pre-sliced into task-specific chunks. This could happen in two different ways, depending on the implementation of the specific connectors. For connectors which have a static set of tasks which doesn’t change at runtime (that’s the case for the <a href="https://debezium.io/">Debezium</a> connectors, for instance), the operator would deploy a short-lived pod on the Kubernetes cluster which runs the actual <code>Connector</code> implementation class and invoke its <code>taskConfigs(int maxTasks)</code> method <i class="conum" data-value="3"></i>. This could be implemented using a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">Kubernetes job</a>, for instance. Once the operator has received the result (a map with one configuration entry per task), the connector pod can be stopped again and the operator will deploy one pod for each configured task, passing its specific configuration to the pod.</p>
</div>
<div class="paragraph">
<p>Things get a bit more tricky if connectors dynamically change the number and/or configuration of tasks at runtime, which also is possible with Connect. For instance, that’s the case for the <a href="https://github.com/apache/kafka/blob/trunk/connect/mirror/README.md">MirrorMaker 2</a> connector. Such a connector typically spins up a dedicated thread upon start-up which monitors some input resource. If that resource’s state changes (say, a new topic to replicate gets detected by MirrorMaker 2), it invokes the <code>ConnectorContext::requestTaskReconfiguration()</code> method, which in turn lets Connect retrieve the task configuration from the connector. This requires a permanently running pod for that connector class <i class="conum" data-value="4"></i>. Right now, there’d be no way for the operator to know whether that connector pod can be short-lived (static task set) or must be long-lived (dynamic task set). Either Connect itself would define some means of metadata for connectors to declare that information, or it could be part of the Kubernetes custom resource for a connector described in the next section.</p>
</div>
<div class="paragraph">
<p>The configuration of connectors would happen — the Kubernetes way — via <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">custom resources</a>. This could look rather similar to how Connect and connectors are deployed via CRs with Strimzi today; the only difference being that there’d be one CR which describes both Connect (and the resource limits to apply, the connector archive to run) and the actual connector configuration. Here’s an example how that could look like (again, that’s a sketch of how such a CR could look like, this won’t work with Strimzi right now):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="yaml"><table class="linenotable"><tbody><tr><td class="linenos gl"><pre class="lineno"> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre></td><td class="code"><pre><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kafka.strimzi.io/v1beta2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">KafkaConnector</span>
<span class="na">metadata</span><span class="pi">:</span>
 <span class="na">name</span><span class="pi">:</span> <span class="s">debezium-connect-cluster</span>
<span class="na">spec</span><span class="pi">:</span>
 <span class="na">version</span><span class="pi">:</span> <span class="s">3.2.0</span>
 <span class="na">bootstrapServers</span><span class="pi">:</span> <span class="s">debezium-cluster-kafka-bootstrap:9092</span>
 <span class="na">config</span><span class="pi">:</span>
   <span class="na">config.providers</span><span class="pi">:</span> <span class="s">secrets</span>
   <span class="na">config.providers.secrets.class</span><span class="pi">:</span> <span class="s">io.strimzi.kafka.KubernetesSecretConfigProvider</span>
   <span class="na">group.id</span><span class="pi">:</span> <span class="s">connect-cluster</span>
   <span class="na">offset.storage.topic</span><span class="pi">:</span> <span class="s">connect-cluster-offsets</span>
   <span class="na">config.storage.topic</span><span class="pi">:</span> <span class="s">connect-cluster-configs</span>
   <span class="na">status.storage.topic</span><span class="pi">:</span> <span class="s">connect-cluster-status</span>
   <span class="na">connector</span><span class="pi">:</span>
     <span class="na">class</span><span class="pi">:</span> <span class="s">io.debezium.connector.mysql.MySqlConnector</span>
     <span class="na">tasksMax</span><span class="pi">:</span> <span class="m">1</span>
     <span class="na">database.hostname</span><span class="pi">:</span> <span class="s">mysql</span>
     <span class="na">database.port</span><span class="pi">:</span> <span class="m">3306</span>
     <span class="na">database.user</span><span class="pi">:</span> <span class="s">${secrets:debezium-example/debezium-secret:username}</span>
     <span class="na">database.password</span><span class="pi">:</span> <span class="s">${secrets:debezium-example/debezium-secret:password}</span>
     <span class="na">database.server.id</span><span class="pi">:</span> <span class="m">184054</span>
     <span class="na">database.server.name</span><span class="pi">:</span> <span class="s">mysql</span>
     <span class="na">database.include.list</span><span class="pi">:</span> <span class="s">inventory</span>
     <span class="na">database.history.kafka.bootstrap.servers</span><span class="pi">:</span> <span class="s">debezium-cluster-kafka-bootstrap:9092</span>
     <span class="na">database.history.kafka.topic</span><span class="pi">:</span> <span class="s">schema-changes.inventory</span>
 <span class="na">build</span><span class="pi">:</span>
   <span class="na">output</span><span class="pi">:</span>
     <span class="na">type</span><span class="pi">:</span> <span class="s">docker</span>
     <span class="na">image</span><span class="pi">:</span> <span class="s">10.110.154.103/debezium-connect-mysql:latest</span>
   <span class="na">plugins</span><span class="pi">:</span>
     <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">debezium-mysql-connector</span>
       <span class="na">artifacts</span><span class="pi">:</span>
         <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">tgz</span>
           <span class="na">url</span><span class="pi">:</span> <span class="s">https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/1.9.0.Final/debezium-connector-mysql-1.9.0.Final-plugin.tar.gz</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>The operator would react to the creation, modification, or deletion of this resource, retrieve the (initial) task configuration as described above and spin up corresponding connector and task pods. To stop or restart a connector or task, the user would update the resource state accordingly, upon which the operator would stop and restart the affected pod(s).</p>
</div>
<div class="paragraph">
<p>Such an operator-based design addresses all the concerns for running Connect on Kubernetes identified above:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Only one component in charge of workload distribution:</em> by removing Connect’s own clustering layer from the picture, the scheduling of tasks to compute resources is completely left to one component, the operator; it will determine the number and configuration of tasks to be executed and schedule a pod for each of them; regular health checks can be used for monitoring the state of each task, restarting failed task pods as needed; a degraded health state should be exposed if a connector task is in a retrying loop, so as to make this situation apparent at the Kubernetes level; if a pod crashes, it can be restarted by the operator on the same or another node of the Kubernetes cluster, not requiring any kind of task rebalancing from a Connect perspective. Node selectors could be used to pin a task to specific node groups, e.g. in a specific region or availability zone.</p>
</li>
<li>
<p><em>One JVM process and Kubernetes pod per task:</em> by launching each task in its own process, all the isolation issues discussed above can be avoided, preventing multiple tasks from negatively impacting each other. If needed, Kubernetes resource limits can be put in place in order to effectively cap the resources available to one particular task, such as CPU and RAM, while also allowing to schedule all the task pods tightly packed onto the compute nodes, making efficient use of the available resources. As each process runs exactly one task, log files are easy to consume and analyze. Scaling out can happen by increasing a single configuration parameter in the CR, and a corresponding number of task pods will be deployed by the operator. Thread leaks become a non-issue too, as there would be no notion of stopping or pausing a task; instead, just the pod itself would be stopped for that purpose, terminating the JVM process running inside of it. On the downside, the overall memory consumption across all the tasks would be increased, as there would be no amortization of Connect classes loaded into JVM processes shared by multiple tasks. Considering the significant advantages of process-based isolation, this seems like an acceptable trade-off, just as Java application developers largely have moved on from the model of co-deploying several applications into shared application server instances.</p>
</li>
<li>
<p><em>Immutable design:</em> by driving configuration solely through Kubernetes resources and passing the resulting Connect configuration as parameters to the Connect process upon start-up, there’s no need for exposing a mutating REST API (there’d still be a REST endpoint exposing health information), making things more secure and potentially less complex internally, as the entire machinery for pausing/resuming, dynamically reconfiguring and stopping tasks could be removed. At any time, a connector’s configuration would be apparent by examining its CR, which ideally should be sourced from an SCM (GitOps).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Looking further out into the future, such a design for making Kafka Connect Kubernetes-native would also allow for other, potentially very interesting explorations: for instance one could compile connectors into native binaries using <a href="https://www.graalvm.org/">GraalVM</a>, resulting in a significantly lower consumption of memory and faster start-up times (e.g. when reconfiguring a connector and subsequently restarting the corresponding pod), making that model very interesting for densely packed Kubernetes environments. A buildtime toolkit like <a href="https://quarkus.io/">Quarkus</a> could be used for producing specifically tailored executables, which run exactly one single connector task on top of the Connect framework infrastructure, a bit similar to how <a href="https://camel.apache.org/camel-k/1.9.x/index.html">Camel-K</a> works under the hood. Ultimately, such Kubernetes-native design could even open up the door to Kafka connectors being built in languages and runtimes other than Java and the JVM, similar to the route explored by the <a href="https://conduit.io/">Conduit</a> project.</p>
</div>
<div class="paragraph">
<p>If you think this all sounds exciting and should become a reality, I would love to hear from you. One aspect of specific interest will be which of the proposed changes would have to be implemented within Kafka Connect itself (vs. a separate operator project, for instance under the Strimzi umbrella), without disrupting non-Kubernetes users. In any case, it would be amazing to see the Kafka community at large take its steps towards making Connect truly Kubernetes-native and fully taking advantage of this immensely successful container orchestration platform!</p>
</div>
<div class="paragraph">
<p><em>Many thanks to Tom Bentley, <a href="https://twitter.com/tomncooper">Tom Cooper</a>, <a href="https://twitter.com/DolanRyanne">Ryanne Dolan</a>, <a href="https://twitter.com/nbuesing">Neil Buesing</a>, <a href="https://twitter.com/MickaelMaison">Mickael Maison</a>, <a href="https://twitter.com/eye0fRa">Mattia Mascia</a>, <a href="https://twitter.com/ppatierno">Paolo Patierno</a>, <a href="https://twitter.com/scholzj">Jakub Scholz</a>, and <a href="https://twitter.com/KateStanley91">Kate Stanley</a> for providing their feedback while writing this post!</em></p>
</div>
</div>
</div>

			</div>

			<div class="post-tags">
				
					
				
			</div>
		</div><div id="disqus_thread">
  <script src="https://giscus.app/client.js"
    data-repo="gunnarmorling/discussions.morling.dev"
    data-repo-id="R_kgDOGXzqNQ"
    data-category="Announcements"
    data-category-id="DIC_kwDOGXzqNc4B_2Pq"
    data-mapping="title"
    data-reactions-enabled="1"
    data-emit-metadata="0"
    data-theme="light"
    data-lang="en"
    crossorigin="anonymous"
    async>
  </script>
</div>

<noscript>Please enable JavaScript, or join the <a href="https://github.com/gunnarmorling/discussions.morling.dev/discussions/">discussion on GitHub</a>.</noscript>
</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> © 2019 - 2025 Gunnar Morling |  Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons BY-SA 4.0</a> | <a href="/ai">How I use (and don't use) AI</a></div>
	</nav>
</div><script>
	mediumZoom(document.querySelectorAll('div.imageblock > div.content > img'))
</script>

</body>
</html>
